{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import warnings\n",
    "import random\n",
    "warnings.filterwarnings('ignore')\n",
    "# get_ipython().run_line_magic('matplotlib', 'inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./intrusion_detection/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>service</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>num_root</th>\n",
       "      <th>num_file_creations</th>\n",
       "      <th>num_access_files</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>xAttack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>193</td>\n",
       "      <td>441</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>dos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>167</td>\n",
       "      <td>9724</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1339</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  service  src_bytes  dst_bytes  hot  num_failed_logins  \\\n",
       "0         0       25        193        441    0                  0   \n",
       "1         0       38          0          0    0                  0   \n",
       "2         0       25        167       9724    0                  0   \n",
       "3         0       20       1339          0    0                  0   \n",
       "4         0       37          0          0    0                  0   \n",
       "\n",
       "   num_compromised  num_root  num_file_creations  num_access_files   ...     \\\n",
       "0                0         0                   0                 0   ...      \n",
       "1                0         0                   0                 0   ...      \n",
       "2                0         0                   0                 0   ...      \n",
       "3                0         0                   0                 0   ...      \n",
       "4                0         0                   0                 0   ...      \n",
       "\n",
       "   dst_host_srv_count  dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0                 255                    1.00                    0.00   \n",
       "1                   1                    0.00                    0.07   \n",
       "2                 255                    1.00                    0.00   \n",
       "3                  31                    0.23                    0.04   \n",
       "4                  25                    0.10                    0.05   \n",
       "\n",
       "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                         0.07                         0.04   \n",
       "1                         0.00                         0.00   \n",
       "2                         0.03                         0.06   \n",
       "3                         0.23                         0.00   \n",
       "4                         0.00                         0.00   \n",
       "\n",
       "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0                  0.00                      0.04                   0.0   \n",
       "1                  0.00                      0.00                   1.0   \n",
       "2                  0.00                      0.00                   0.0   \n",
       "3                  0.02                      0.00                   0.0   \n",
       "4                  1.00                      1.00                   0.0   \n",
       "\n",
       "   dst_host_srv_rerror_rate  xAttack  \n",
       "0                       0.0   normal  \n",
       "1                       1.0      dos  \n",
       "2                       0.0   normal  \n",
       "3                       0.0   normal  \n",
       "4                       0.0      dos  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>service</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>num_root</th>\n",
       "      <th>num_file_creations</th>\n",
       "      <th>num_access_files</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_count</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>24998.000000</td>\n",
       "      <td>24998.000000</td>\n",
       "      <td>2.499800e+04</td>\n",
       "      <td>2.499800e+04</td>\n",
       "      <td>24998.000000</td>\n",
       "      <td>24998.000000</td>\n",
       "      <td>24998.000000</td>\n",
       "      <td>24998.000000</td>\n",
       "      <td>24998.000000</td>\n",
       "      <td>24998.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>24998.000000</td>\n",
       "      <td>24998.000000</td>\n",
       "      <td>24998.000000</td>\n",
       "      <td>24998.000000</td>\n",
       "      <td>24998.000000</td>\n",
       "      <td>24998.000000</td>\n",
       "      <td>24998.000000</td>\n",
       "      <td>24998.000000</td>\n",
       "      <td>24998.000000</td>\n",
       "      <td>24998.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>310.648452</td>\n",
       "      <td>32.024842</td>\n",
       "      <td>2.442409e+04</td>\n",
       "      <td>3.305597e+03</td>\n",
       "      <td>0.193535</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.229418</td>\n",
       "      <td>0.251700</td>\n",
       "      <td>0.014841</td>\n",
       "      <td>0.004360</td>\n",
       "      <td>...</td>\n",
       "      <td>182.405832</td>\n",
       "      <td>115.254580</td>\n",
       "      <td>0.520648</td>\n",
       "      <td>0.083117</td>\n",
       "      <td>0.148392</td>\n",
       "      <td>0.032109</td>\n",
       "      <td>0.284272</td>\n",
       "      <td>0.278418</td>\n",
       "      <td>0.118272</td>\n",
       "      <td>0.119189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2712.235502</td>\n",
       "      <td>16.493033</td>\n",
       "      <td>2.420103e+06</td>\n",
       "      <td>8.301712e+04</td>\n",
       "      <td>2.127846</td>\n",
       "      <td>0.045594</td>\n",
       "      <td>10.457662</td>\n",
       "      <td>11.545358</td>\n",
       "      <td>0.531652</td>\n",
       "      <td>0.098905</td>\n",
       "      <td>...</td>\n",
       "      <td>99.046209</td>\n",
       "      <td>110.659088</td>\n",
       "      <td>0.449020</td>\n",
       "      <td>0.188442</td>\n",
       "      <td>0.309335</td>\n",
       "      <td>0.111102</td>\n",
       "      <td>0.444531</td>\n",
       "      <td>0.445374</td>\n",
       "      <td>0.306349</td>\n",
       "      <td>0.317858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>4.400000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>2.790000e+02</td>\n",
       "      <td>5.310000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>42862.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>3.817091e+08</td>\n",
       "      <td>5.150836e+06</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>884.000000</td>\n",
       "      <td>975.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           duration       service     src_bytes     dst_bytes           hot  \\\n",
       "count  24998.000000  24998.000000  2.499800e+04  2.499800e+04  24998.000000   \n",
       "mean     310.648452     32.024842  2.442409e+04  3.305597e+03      0.193535   \n",
       "std     2712.235502     16.493033  2.420103e+06  8.301712e+04      2.127846   \n",
       "min        0.000000      1.000000  0.000000e+00  0.000000e+00      0.000000   \n",
       "25%        0.000000     20.000000  0.000000e+00  0.000000e+00      0.000000   \n",
       "50%        0.000000     25.000000  4.400000e+01  0.000000e+00      0.000000   \n",
       "75%        0.000000     50.000000  2.790000e+02  5.310000e+02      0.000000   \n",
       "max    42862.000000     70.000000  3.817091e+08  5.150836e+06     77.000000   \n",
       "\n",
       "       num_failed_logins  num_compromised      num_root  num_file_creations  \\\n",
       "count       24998.000000     24998.000000  24998.000000        24998.000000   \n",
       "mean            0.001200         0.229418      0.251700            0.014841   \n",
       "std             0.045594        10.457662     11.545358            0.531652   \n",
       "min             0.000000         0.000000      0.000000            0.000000   \n",
       "25%             0.000000         0.000000      0.000000            0.000000   \n",
       "50%             0.000000         0.000000      0.000000            0.000000   \n",
       "75%             0.000000         0.000000      0.000000            0.000000   \n",
       "max             4.000000       884.000000    975.000000           40.000000   \n",
       "\n",
       "       num_access_files            ...             dst_host_count  \\\n",
       "count      24998.000000            ...               24998.000000   \n",
       "mean           0.004360            ...                 182.405832   \n",
       "std            0.098905            ...                  99.046209   \n",
       "min            0.000000            ...                   0.000000   \n",
       "25%            0.000000            ...                  84.000000   \n",
       "50%            0.000000            ...                 255.000000   \n",
       "75%            0.000000            ...                 255.000000   \n",
       "max            8.000000            ...                 255.000000   \n",
       "\n",
       "       dst_host_srv_count  dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "count        24998.000000            24998.000000            24998.000000   \n",
       "mean           115.254580                0.520648                0.083117   \n",
       "std            110.659088                0.449020                0.188442   \n",
       "min              0.000000                0.000000                0.000000   \n",
       "25%             10.000000                0.050000                0.000000   \n",
       "50%             62.000000                0.510000                0.030000   \n",
       "75%            255.000000                1.000000                0.070000   \n",
       "max            255.000000                1.000000                1.000000   \n",
       "\n",
       "       dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "count                 24998.000000                 24998.000000   \n",
       "mean                      0.148392                     0.032109   \n",
       "std                       0.309335                     0.111102   \n",
       "min                       0.000000                     0.000000   \n",
       "25%                       0.000000                     0.000000   \n",
       "50%                       0.000000                     0.000000   \n",
       "75%                       0.060000                     0.020000   \n",
       "max                       1.000000                     1.000000   \n",
       "\n",
       "       dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "count          24998.000000              24998.000000          24998.000000   \n",
       "mean               0.284272                  0.278418              0.118272   \n",
       "std                0.444531                  0.445374              0.306349   \n",
       "min                0.000000                  0.000000              0.000000   \n",
       "25%                0.000000                  0.000000              0.000000   \n",
       "50%                0.000000                  0.000000              0.000000   \n",
       "75%                1.000000                  1.000000              0.000000   \n",
       "max                1.000000                  1.000000              1.000000   \n",
       "\n",
       "       dst_host_srv_rerror_rate  \n",
       "count              24998.000000  \n",
       "mean                   0.119189  \n",
       "std                    0.317858  \n",
       "min                    0.000000  \n",
       "25%                    0.000000  \n",
       "50%                    0.000000  \n",
       "75%                    0.000000  \n",
       "max                    1.000000  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class preProcessor:\n",
    "    def __init__(self):\n",
    "        self.scalar = StandardScaler()\n",
    "    def fit(self, df, features):\n",
    "        # Separating out the features\n",
    "        x = df[features]\n",
    "        self.scalar = StandardScaler().fit(x)\n",
    "    def transform(self, df, features):\n",
    "        rest = [col for col in df.columns.values if col not in features]\n",
    "        res = pd.DataFrame(self.scalar.transform(df), columns=features)\n",
    "#         print(res)\n",
    "        res[rest] = df[rest]\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['duration', 'service', 'src_bytes', 'dst_bytes', 'hot',\n",
       "       'num_failed_logins', 'num_compromised', 'num_root',\n",
       "       'num_file_creations', 'num_access_files', 'count', 'srv_count',\n",
       "       'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate',\n",
       "       'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate',\n",
       "       'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
       "       'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
       "       'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
       "       'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
       "       'dst_host_srv_rerror_rate'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'xAttack'\n",
    "features = df.columns.values[[df.columns.values != 'xAttack']]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = preProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.fit(df[features], features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_standard = processor.transform(df[features], features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>service</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>num_root</th>\n",
       "      <th>num_file_creations</th>\n",
       "      <th>num_access_files</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_count</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>-0.425936</td>\n",
       "      <td>-0.010013</td>\n",
       "      <td>-0.034507</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.690213</td>\n",
       "      <td>1.262872</td>\n",
       "      <td>1.067572</td>\n",
       "      <td>-0.441083</td>\n",
       "      <td>-0.253425</td>\n",
       "      <td>0.071030</td>\n",
       "      <td>-0.639500</td>\n",
       "      <td>-0.535332</td>\n",
       "      <td>-0.386077</td>\n",
       "      <td>-0.374982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>0.362291</td>\n",
       "      <td>-0.010092</td>\n",
       "      <td>-0.039819</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.732947</td>\n",
       "      <td>-1.032512</td>\n",
       "      <td>-1.159545</td>\n",
       "      <td>-0.069609</td>\n",
       "      <td>-0.479722</td>\n",
       "      <td>-0.289006</td>\n",
       "      <td>-0.639500</td>\n",
       "      <td>-0.625146</td>\n",
       "      <td>2.878240</td>\n",
       "      <td>2.771138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>-0.425936</td>\n",
       "      <td>-0.010023</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.447897</td>\n",
       "      <td>1.262872</td>\n",
       "      <td>1.067572</td>\n",
       "      <td>-0.441083</td>\n",
       "      <td>-0.382738</td>\n",
       "      <td>0.251048</td>\n",
       "      <td>-0.639500</td>\n",
       "      <td>-0.625146</td>\n",
       "      <td>-0.386077</td>\n",
       "      <td>-0.374982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>-0.729101</td>\n",
       "      <td>-0.009539</td>\n",
       "      <td>-0.039819</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.488729</td>\n",
       "      <td>-0.761404</td>\n",
       "      <td>-0.647308</td>\n",
       "      <td>-0.228812</td>\n",
       "      <td>0.263823</td>\n",
       "      <td>-0.289006</td>\n",
       "      <td>-0.594507</td>\n",
       "      <td>-0.625146</td>\n",
       "      <td>-0.386077</td>\n",
       "      <td>-0.374982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>0.301658</td>\n",
       "      <td>-0.010092</td>\n",
       "      <td>-0.039819</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.732947</td>\n",
       "      <td>-0.815626</td>\n",
       "      <td>-0.936833</td>\n",
       "      <td>-0.175745</td>\n",
       "      <td>-0.479722</td>\n",
       "      <td>-0.289006</td>\n",
       "      <td>1.610108</td>\n",
       "      <td>1.620205</td>\n",
       "      <td>-0.386077</td>\n",
       "      <td>-0.374982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration   service  src_bytes  dst_bytes       hot  num_failed_logins  \\\n",
       "0 -0.114538 -0.425936  -0.010013  -0.034507 -0.090956          -0.026322   \n",
       "1 -0.114538  0.362291  -0.010092  -0.039819 -0.090956          -0.026322   \n",
       "2 -0.114538 -0.425936  -0.010023   0.077316 -0.090956          -0.026322   \n",
       "3 -0.114538 -0.729101  -0.009539  -0.039819 -0.090956          -0.026322   \n",
       "4 -0.114538  0.301658  -0.010092  -0.039819 -0.090956          -0.026322   \n",
       "\n",
       "   num_compromised  num_root  num_file_creations  num_access_files  \\\n",
       "0        -0.021938 -0.021801           -0.027916         -0.044087   \n",
       "1        -0.021938 -0.021801           -0.027916         -0.044087   \n",
       "2        -0.021938 -0.021801           -0.027916         -0.044087   \n",
       "3        -0.021938 -0.021801           -0.027916         -0.044087   \n",
       "4        -0.021938 -0.021801           -0.027916         -0.044087   \n",
       "\n",
       "             ...             dst_host_count  dst_host_srv_count  \\\n",
       "0            ...                  -1.690213            1.262872   \n",
       "1            ...                   0.732947           -1.032512   \n",
       "2            ...                  -1.447897            1.262872   \n",
       "3            ...                  -0.488729           -0.761404   \n",
       "4            ...                   0.732947           -0.815626   \n",
       "\n",
       "   dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0                1.067572               -0.441083   \n",
       "1               -1.159545               -0.069609   \n",
       "2                1.067572               -0.441083   \n",
       "3               -0.647308               -0.228812   \n",
       "4               -0.936833               -0.175745   \n",
       "\n",
       "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                    -0.253425                     0.071030   \n",
       "1                    -0.479722                    -0.289006   \n",
       "2                    -0.382738                     0.251048   \n",
       "3                     0.263823                    -0.289006   \n",
       "4                    -0.479722                    -0.289006   \n",
       "\n",
       "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0             -0.639500                 -0.535332             -0.386077   \n",
       "1             -0.639500                 -0.625146              2.878240   \n",
       "2             -0.639500                 -0.625146             -0.386077   \n",
       "3             -0.594507                 -0.625146             -0.386077   \n",
       "4              1.610108                  1.620205             -0.386077   \n",
       "\n",
       "   dst_host_srv_rerror_rate  \n",
       "0                 -0.374982  \n",
       "1                  2.771138  \n",
       "2                 -0.374982  \n",
       "3                 -0.374982  \n",
       "4                 -0.374982  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_standard.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_standard[target] = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>service</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>num_root</th>\n",
       "      <th>num_file_creations</th>\n",
       "      <th>num_access_files</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>xAttack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>-0.425936</td>\n",
       "      <td>-0.010013</td>\n",
       "      <td>-0.034507</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>1.262872</td>\n",
       "      <td>1.067572</td>\n",
       "      <td>-0.441083</td>\n",
       "      <td>-0.253425</td>\n",
       "      <td>0.071030</td>\n",
       "      <td>-0.639500</td>\n",
       "      <td>-0.535332</td>\n",
       "      <td>-0.386077</td>\n",
       "      <td>-0.374982</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>0.362291</td>\n",
       "      <td>-0.010092</td>\n",
       "      <td>-0.039819</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.032512</td>\n",
       "      <td>-1.159545</td>\n",
       "      <td>-0.069609</td>\n",
       "      <td>-0.479722</td>\n",
       "      <td>-0.289006</td>\n",
       "      <td>-0.639500</td>\n",
       "      <td>-0.625146</td>\n",
       "      <td>2.878240</td>\n",
       "      <td>2.771138</td>\n",
       "      <td>dos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>-0.425936</td>\n",
       "      <td>-0.010023</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>1.262872</td>\n",
       "      <td>1.067572</td>\n",
       "      <td>-0.441083</td>\n",
       "      <td>-0.382738</td>\n",
       "      <td>0.251048</td>\n",
       "      <td>-0.639500</td>\n",
       "      <td>-0.625146</td>\n",
       "      <td>-0.386077</td>\n",
       "      <td>-0.374982</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>-0.729101</td>\n",
       "      <td>-0.009539</td>\n",
       "      <td>-0.039819</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.761404</td>\n",
       "      <td>-0.647308</td>\n",
       "      <td>-0.228812</td>\n",
       "      <td>0.263823</td>\n",
       "      <td>-0.289006</td>\n",
       "      <td>-0.594507</td>\n",
       "      <td>-0.625146</td>\n",
       "      <td>-0.386077</td>\n",
       "      <td>-0.374982</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>0.301658</td>\n",
       "      <td>-0.010092</td>\n",
       "      <td>-0.039819</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.815626</td>\n",
       "      <td>-0.936833</td>\n",
       "      <td>-0.175745</td>\n",
       "      <td>-0.479722</td>\n",
       "      <td>-0.289006</td>\n",
       "      <td>1.610108</td>\n",
       "      <td>1.620205</td>\n",
       "      <td>-0.386077</td>\n",
       "      <td>-0.374982</td>\n",
       "      <td>dos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration   service  src_bytes  dst_bytes       hot  num_failed_logins  \\\n",
       "0 -0.114538 -0.425936  -0.010013  -0.034507 -0.090956          -0.026322   \n",
       "1 -0.114538  0.362291  -0.010092  -0.039819 -0.090956          -0.026322   \n",
       "2 -0.114538 -0.425936  -0.010023   0.077316 -0.090956          -0.026322   \n",
       "3 -0.114538 -0.729101  -0.009539  -0.039819 -0.090956          -0.026322   \n",
       "4 -0.114538  0.301658  -0.010092  -0.039819 -0.090956          -0.026322   \n",
       "\n",
       "   num_compromised  num_root  num_file_creations  num_access_files   ...     \\\n",
       "0        -0.021938 -0.021801           -0.027916         -0.044087   ...      \n",
       "1        -0.021938 -0.021801           -0.027916         -0.044087   ...      \n",
       "2        -0.021938 -0.021801           -0.027916         -0.044087   ...      \n",
       "3        -0.021938 -0.021801           -0.027916         -0.044087   ...      \n",
       "4        -0.021938 -0.021801           -0.027916         -0.044087   ...      \n",
       "\n",
       "   dst_host_srv_count  dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0            1.262872                1.067572               -0.441083   \n",
       "1           -1.032512               -1.159545               -0.069609   \n",
       "2            1.262872                1.067572               -0.441083   \n",
       "3           -0.761404               -0.647308               -0.228812   \n",
       "4           -0.815626               -0.936833               -0.175745   \n",
       "\n",
       "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                    -0.253425                     0.071030   \n",
       "1                    -0.479722                    -0.289006   \n",
       "2                    -0.382738                     0.251048   \n",
       "3                     0.263823                    -0.289006   \n",
       "4                    -0.479722                    -0.289006   \n",
       "\n",
       "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0             -0.639500                 -0.535332             -0.386077   \n",
       "1             -0.639500                 -0.625146              2.878240   \n",
       "2             -0.639500                 -0.625146             -0.386077   \n",
       "3             -0.594507                 -0.625146             -0.386077   \n",
       "4              1.610108                  1.620205             -0.386077   \n",
       "\n",
       "   dst_host_srv_rerror_rate  xAttack  \n",
       "0                 -0.374982   normal  \n",
       "1                  2.771138      dos  \n",
       "2                 -0.374982   normal  \n",
       "3                 -0.374982   normal  \n",
       "4                 -0.374982      dos  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_standard.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART-1 My PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyPCA:\n",
    "    def __init__(self, n_components = None):\n",
    "        self.n_components = n_components\n",
    "    def fit(self, df):\n",
    "        margin = 10\n",
    "        self.cols = df.columns.values\n",
    "        x = df.values\n",
    "        covar = np.dot(x.T,x)\n",
    "        self.u, self.s, self.vh = np.linalg.svd(x, full_matrices=False)\n",
    "        if(self.n_components is None):\n",
    "            k = len(self.s)\n",
    "        else:\n",
    "            k = self.n_components\n",
    "        cum_sum = 0.0\n",
    "        tot_sum = np.sum(np.square(self.s))\n",
    "        for i in range(len(self.s)):\n",
    "            cum_sum += self.s[i]**2\n",
    "            if(cum_sum/tot_sum*100 >= 90):\n",
    "                self.n_components = i + 1\n",
    "                break\n",
    "        self.V = self.vh.T[:,:self.n_components]\n",
    "    def transform(self, df):\n",
    "        new_cols = ['PCA_']*len(self.V[0])\n",
    "        for i in range(len(new_cols)):\n",
    "            new_cols[i] = new_cols[i] + str(i+1)\n",
    "        return pd.DataFrame(np.dot(df,self.V),columns=new_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "myPCA = MyPCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "myPCA.fit(df_standard[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.23233278, 0.40004825, 0.49014959, 0.55525906, 0.60602914,\n",
       "       0.65238779, 0.69158857, 0.72800063, 0.76269096, 0.79709466,\n",
       "       0.83029625, 0.86198573, 0.88670879, 0.90931903, 0.92645134,\n",
       "       0.94188281, 0.95609327, 0.96995871, 0.98186236, 0.98911049,\n",
       "       0.9924583 , 0.99475072, 0.99655022, 0.99791726, 0.99891386,\n",
       "       0.99947831, 0.99980557, 0.99996538, 1.        ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cumsum((np.square(myPCA.s)))/np.sum((np.square(myPCA.s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>service</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>num_root</th>\n",
       "      <th>num_file_creations</th>\n",
       "      <th>num_access_files</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>xAttack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>-0.425936</td>\n",
       "      <td>-0.010013</td>\n",
       "      <td>-0.034507</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>1.262872</td>\n",
       "      <td>1.067572</td>\n",
       "      <td>-0.441083</td>\n",
       "      <td>-0.253425</td>\n",
       "      <td>0.071030</td>\n",
       "      <td>-0.639500</td>\n",
       "      <td>-0.535332</td>\n",
       "      <td>-0.386077</td>\n",
       "      <td>-0.374982</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>0.362291</td>\n",
       "      <td>-0.010092</td>\n",
       "      <td>-0.039819</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.032512</td>\n",
       "      <td>-1.159545</td>\n",
       "      <td>-0.069609</td>\n",
       "      <td>-0.479722</td>\n",
       "      <td>-0.289006</td>\n",
       "      <td>-0.639500</td>\n",
       "      <td>-0.625146</td>\n",
       "      <td>2.878240</td>\n",
       "      <td>2.771138</td>\n",
       "      <td>dos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>-0.425936</td>\n",
       "      <td>-0.010023</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>1.262872</td>\n",
       "      <td>1.067572</td>\n",
       "      <td>-0.441083</td>\n",
       "      <td>-0.382738</td>\n",
       "      <td>0.251048</td>\n",
       "      <td>-0.639500</td>\n",
       "      <td>-0.625146</td>\n",
       "      <td>-0.386077</td>\n",
       "      <td>-0.374982</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>-0.729101</td>\n",
       "      <td>-0.009539</td>\n",
       "      <td>-0.039819</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.761404</td>\n",
       "      <td>-0.647308</td>\n",
       "      <td>-0.228812</td>\n",
       "      <td>0.263823</td>\n",
       "      <td>-0.289006</td>\n",
       "      <td>-0.594507</td>\n",
       "      <td>-0.625146</td>\n",
       "      <td>-0.386077</td>\n",
       "      <td>-0.374982</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.114538</td>\n",
       "      <td>0.301658</td>\n",
       "      <td>-0.010092</td>\n",
       "      <td>-0.039819</td>\n",
       "      <td>-0.090956</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.027916</td>\n",
       "      <td>-0.044087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.815626</td>\n",
       "      <td>-0.936833</td>\n",
       "      <td>-0.175745</td>\n",
       "      <td>-0.479722</td>\n",
       "      <td>-0.289006</td>\n",
       "      <td>1.610108</td>\n",
       "      <td>1.620205</td>\n",
       "      <td>-0.386077</td>\n",
       "      <td>-0.374982</td>\n",
       "      <td>dos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration   service  src_bytes  dst_bytes       hot  num_failed_logins  \\\n",
       "0 -0.114538 -0.425936  -0.010013  -0.034507 -0.090956          -0.026322   \n",
       "1 -0.114538  0.362291  -0.010092  -0.039819 -0.090956          -0.026322   \n",
       "2 -0.114538 -0.425936  -0.010023   0.077316 -0.090956          -0.026322   \n",
       "3 -0.114538 -0.729101  -0.009539  -0.039819 -0.090956          -0.026322   \n",
       "4 -0.114538  0.301658  -0.010092  -0.039819 -0.090956          -0.026322   \n",
       "\n",
       "   num_compromised  num_root  num_file_creations  num_access_files   ...     \\\n",
       "0        -0.021938 -0.021801           -0.027916         -0.044087   ...      \n",
       "1        -0.021938 -0.021801           -0.027916         -0.044087   ...      \n",
       "2        -0.021938 -0.021801           -0.027916         -0.044087   ...      \n",
       "3        -0.021938 -0.021801           -0.027916         -0.044087   ...      \n",
       "4        -0.021938 -0.021801           -0.027916         -0.044087   ...      \n",
       "\n",
       "   dst_host_srv_count  dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0            1.262872                1.067572               -0.441083   \n",
       "1           -1.032512               -1.159545               -0.069609   \n",
       "2            1.262872                1.067572               -0.441083   \n",
       "3           -0.761404               -0.647308               -0.228812   \n",
       "4           -0.815626               -0.936833               -0.175745   \n",
       "\n",
       "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                    -0.253425                     0.071030   \n",
       "1                    -0.479722                    -0.289006   \n",
       "2                    -0.382738                     0.251048   \n",
       "3                     0.263823                    -0.289006   \n",
       "4                    -0.479722                    -0.289006   \n",
       "\n",
       "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0             -0.639500                 -0.535332             -0.386077   \n",
       "1             -0.639500                 -0.625146              2.878240   \n",
       "2             -0.639500                 -0.625146             -0.386077   \n",
       "3             -0.594507                 -0.625146             -0.386077   \n",
       "4              1.610108                  1.620205             -0.386077   \n",
       "\n",
       "   dst_host_srv_rerror_rate  xAttack  \n",
       "0                 -0.374982   normal  \n",
       "1                  2.771138      dos  \n",
       "2                 -0.374982   normal  \n",
       "3                 -0.374982   normal  \n",
       "4                 -0.374982      dos  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_standard.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed = myPCA.transform(df_standard[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCA_1</th>\n",
       "      <th>PCA_2</th>\n",
       "      <th>PCA_3</th>\n",
       "      <th>PCA_4</th>\n",
       "      <th>PCA_5</th>\n",
       "      <th>PCA_6</th>\n",
       "      <th>PCA_7</th>\n",
       "      <th>PCA_8</th>\n",
       "      <th>PCA_9</th>\n",
       "      <th>PCA_10</th>\n",
       "      <th>PCA_11</th>\n",
       "      <th>PCA_12</th>\n",
       "      <th>PCA_13</th>\n",
       "      <th>PCA_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.509465</td>\n",
       "      <td>0.952118</td>\n",
       "      <td>-0.080576</td>\n",
       "      <td>0.089474</td>\n",
       "      <td>-0.465568</td>\n",
       "      <td>0.264136</td>\n",
       "      <td>-0.073176</td>\n",
       "      <td>-0.122968</td>\n",
       "      <td>0.115930</td>\n",
       "      <td>-0.037055</td>\n",
       "      <td>-0.015486</td>\n",
       "      <td>-0.085031</td>\n",
       "      <td>-0.478762</td>\n",
       "      <td>0.380058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.193260</td>\n",
       "      <td>-5.598204</td>\n",
       "      <td>-0.270796</td>\n",
       "      <td>1.130964</td>\n",
       "      <td>-0.813104</td>\n",
       "      <td>1.629214</td>\n",
       "      <td>0.541853</td>\n",
       "      <td>0.190286</td>\n",
       "      <td>-0.243678</td>\n",
       "      <td>0.079392</td>\n",
       "      <td>0.028094</td>\n",
       "      <td>-0.064368</td>\n",
       "      <td>0.430118</td>\n",
       "      <td>0.264015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.447100</td>\n",
       "      <td>0.908940</td>\n",
       "      <td>-0.060319</td>\n",
       "      <td>0.031070</td>\n",
       "      <td>-0.822739</td>\n",
       "      <td>0.170783</td>\n",
       "      <td>-0.098461</td>\n",
       "      <td>-0.161767</td>\n",
       "      <td>0.088160</td>\n",
       "      <td>0.084798</td>\n",
       "      <td>0.005995</td>\n",
       "      <td>-0.050482</td>\n",
       "      <td>-0.754361</td>\n",
       "      <td>0.429615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.111758</td>\n",
       "      <td>0.343094</td>\n",
       "      <td>0.004162</td>\n",
       "      <td>-0.266452</td>\n",
       "      <td>-0.166214</td>\n",
       "      <td>-0.596465</td>\n",
       "      <td>-0.015911</td>\n",
       "      <td>0.026994</td>\n",
       "      <td>-0.161913</td>\n",
       "      <td>0.061836</td>\n",
       "      <td>0.050151</td>\n",
       "      <td>0.362929</td>\n",
       "      <td>-0.542295</td>\n",
       "      <td>0.408404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.983967</td>\n",
       "      <td>1.268863</td>\n",
       "      <td>-0.050828</td>\n",
       "      <td>0.252378</td>\n",
       "      <td>0.537147</td>\n",
       "      <td>0.561608</td>\n",
       "      <td>0.278506</td>\n",
       "      <td>0.038172</td>\n",
       "      <td>-0.012687</td>\n",
       "      <td>0.004357</td>\n",
       "      <td>-0.013467</td>\n",
       "      <td>-0.041691</td>\n",
       "      <td>0.072667</td>\n",
       "      <td>-0.071333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PCA_1     PCA_2     PCA_3     PCA_4     PCA_5     PCA_6     PCA_7  \\\n",
       "0  2.509465  0.952118 -0.080576  0.089474 -0.465568  0.264136 -0.073176   \n",
       "1 -1.193260 -5.598204 -0.270796  1.130964 -0.813104  1.629214  0.541853   \n",
       "2  2.447100  0.908940 -0.060319  0.031070 -0.822739  0.170783 -0.098461   \n",
       "3  1.111758  0.343094  0.004162 -0.266452 -0.166214 -0.596465 -0.015911   \n",
       "4 -3.983967  1.268863 -0.050828  0.252378  0.537147  0.561608  0.278506   \n",
       "\n",
       "      PCA_8     PCA_9    PCA_10    PCA_11    PCA_12    PCA_13    PCA_14  \n",
       "0 -0.122968  0.115930 -0.037055 -0.015486 -0.085031 -0.478762  0.380058  \n",
       "1  0.190286 -0.243678  0.079392  0.028094 -0.064368  0.430118  0.264015  \n",
       "2 -0.161767  0.088160  0.084798  0.005995 -0.050482 -0.754361  0.429615  \n",
       "3  0.026994 -0.161913  0.061836  0.050151  0.362929 -0.542295  0.408404  \n",
       "4  0.038172 -0.012687  0.004357 -0.013467 -0.041691  0.072667 -0.071333  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=14, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=14)\n",
    "pca.fit(df_standard[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.509465</td>\n",
       "      <td>-0.952118</td>\n",
       "      <td>-0.080576</td>\n",
       "      <td>0.089474</td>\n",
       "      <td>-0.465568</td>\n",
       "      <td>-0.264136</td>\n",
       "      <td>-0.073176</td>\n",
       "      <td>0.122968</td>\n",
       "      <td>0.115930</td>\n",
       "      <td>-0.037055</td>\n",
       "      <td>0.015486</td>\n",
       "      <td>0.085031</td>\n",
       "      <td>0.478762</td>\n",
       "      <td>-0.380058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.193260</td>\n",
       "      <td>5.598204</td>\n",
       "      <td>-0.270796</td>\n",
       "      <td>1.130964</td>\n",
       "      <td>-0.813104</td>\n",
       "      <td>-1.629214</td>\n",
       "      <td>0.541853</td>\n",
       "      <td>-0.190286</td>\n",
       "      <td>-0.243678</td>\n",
       "      <td>0.079392</td>\n",
       "      <td>-0.028094</td>\n",
       "      <td>0.064368</td>\n",
       "      <td>-0.430118</td>\n",
       "      <td>-0.264015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.447100</td>\n",
       "      <td>-0.908940</td>\n",
       "      <td>-0.060319</td>\n",
       "      <td>0.031070</td>\n",
       "      <td>-0.822739</td>\n",
       "      <td>-0.170783</td>\n",
       "      <td>-0.098461</td>\n",
       "      <td>0.161767</td>\n",
       "      <td>0.088160</td>\n",
       "      <td>0.084798</td>\n",
       "      <td>-0.005995</td>\n",
       "      <td>0.050482</td>\n",
       "      <td>0.754361</td>\n",
       "      <td>-0.429615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.111758</td>\n",
       "      <td>-0.343094</td>\n",
       "      <td>0.004162</td>\n",
       "      <td>-0.266452</td>\n",
       "      <td>-0.166214</td>\n",
       "      <td>0.596465</td>\n",
       "      <td>-0.015911</td>\n",
       "      <td>-0.026994</td>\n",
       "      <td>-0.161913</td>\n",
       "      <td>0.061836</td>\n",
       "      <td>-0.050151</td>\n",
       "      <td>-0.362929</td>\n",
       "      <td>0.542295</td>\n",
       "      <td>-0.408404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.983967</td>\n",
       "      <td>-1.268863</td>\n",
       "      <td>-0.050828</td>\n",
       "      <td>0.252378</td>\n",
       "      <td>0.537147</td>\n",
       "      <td>-0.561608</td>\n",
       "      <td>0.278506</td>\n",
       "      <td>-0.038172</td>\n",
       "      <td>-0.012687</td>\n",
       "      <td>0.004357</td>\n",
       "      <td>0.013467</td>\n",
       "      <td>0.041691</td>\n",
       "      <td>-0.072667</td>\n",
       "      <td>0.071333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -2.509465 -0.952118 -0.080576  0.089474 -0.465568 -0.264136 -0.073176   \n",
       "1  1.193260  5.598204 -0.270796  1.130964 -0.813104 -1.629214  0.541853   \n",
       "2 -2.447100 -0.908940 -0.060319  0.031070 -0.822739 -0.170783 -0.098461   \n",
       "3 -1.111758 -0.343094  0.004162 -0.266452 -0.166214  0.596465 -0.015911   \n",
       "4  3.983967 -1.268863 -0.050828  0.252378  0.537147 -0.561608  0.278506   \n",
       "\n",
       "         7         8         9         10        11        12        13  \n",
       "0  0.122968  0.115930 -0.037055  0.015486  0.085031  0.478762 -0.380058  \n",
       "1 -0.190286 -0.243678  0.079392 -0.028094  0.064368 -0.430118 -0.264015  \n",
       "2  0.161767  0.088160  0.084798 -0.005995  0.050482  0.754361 -0.429615  \n",
       "3 -0.026994 -0.161913  0.061836 -0.050151 -0.362929  0.542295 -0.408404  \n",
       "4 -0.038172 -0.012687  0.004357  0.013467  0.041691 -0.072667  0.071333  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(pca.transform(df_standard[features]))\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23233278 0.16771547 0.09010134 0.06510947 0.05077007 0.04635866\n",
      " 0.03920077 0.03641207 0.03469033 0.03440369 0.03320159 0.03168948\n",
      " 0.02472306 0.02261023]\n"
     ]
    }
   ],
   "source": [
    "print(pca.explained_variance_ratio_)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9093190252147934"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function for Test Train split\n",
    "def splitData(X ,Y, test_size = 0.2, random_state = 10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = test_size ,random_state = random_state)\n",
    "    return (X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spltting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = splitData(df_transformed, df[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_transformed\n",
    "y_train = df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Util Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcPurity(n_clusters, y_pred , y):\n",
    "    labels_ = {}\n",
    "    y_pred = np.array(y_pred)\n",
    "    y = np.array(y)\n",
    "    for i in range(n_clusters):\n",
    "        lst = list(y[y_pred == i])\n",
    "        labels_[i]  = max(set(lst), key=lst.count)\n",
    "    purity = {}\n",
    "    for i in range(n_clusters):\n",
    "        temp = y_pred[y_pred == i]\n",
    "        temp = np.array([labels_[i] for i in temp])\n",
    "        y1 = y[y_pred == i]\n",
    "        purity[i] = len(temp[temp == y1])/len(temp)\n",
    "    return (labels_, purity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART - 2 My K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyKmeans():\n",
    "    def __init__(self, n_clusters = 3, random_state = 0, max_iter=300, tol=0.0001):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.random_state = random_state\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "    \n",
    "    def fit(self, df, y):\n",
    "        np_df = df.values\n",
    "        y = y.values\n",
    "        self.cols = df.columns.values\n",
    "        self.centers = {}\n",
    "        temp = random.sample(range(df.shape[1]),self.n_clusters)\n",
    "        for i in range(len(temp)):\n",
    "            self.centers[i] = np_df[temp[i]]\n",
    "        for i in range(self.max_iter):\n",
    "            self.classes = {}\n",
    "            self.indexes = {}\n",
    "            prev_centers = dict(self.centers)\n",
    "            for t in range(self.n_clusters):\n",
    "                self.classes[t] = []\n",
    "                self.indexes[t] = []\n",
    "            start = 0\n",
    "            for row in np_df:\n",
    "                dists = [np.linalg.norm(row-self.centers[c]) for c in self.centers]\n",
    "                index = dists.index(min(dists))\n",
    "                self.classes[index].append(row)\n",
    "                self.indexes[index].append(start)\n",
    "                start += 1\n",
    "            for t in range(len(self.centers)):\n",
    "                self.centers[t] = np.average(self.classes[t], axis = 0)\n",
    "            flag = True\n",
    "            error = 0.00\n",
    "            for t in range(len(self.centers)):\n",
    "                e = np.linalg.norm(prev_centers[t]-self.centers[t])\n",
    "                error += e\n",
    "                if(e > self.tol):\n",
    "                    flag = False\n",
    "            print(\"Iteration: {0}\".format(i))\n",
    "            print(\"Error: {0}\".format(float(error)))\n",
    "            if(flag):\n",
    "                break\n",
    "        self.labels_ = {}\n",
    "        for t in range(self.n_clusters):\n",
    "            lst = list(y[self.indexes[t]])\n",
    "            self.labels_[t] = max(set(lst), key=lst.count)\n",
    "        self.purity = {}\n",
    "        for t in range(self.n_clusters):\n",
    "            self.purity[t] = len(y[self.indexes[t]][y[self.indexes[t]] == self.labels_[t]])/len(self.classes[t])\n",
    "    \n",
    "    def predict_row(self, row):\n",
    "        dists = [np.linalg.norm(row-self.centers[c]) for c in self.centers]\n",
    "        index = dists.index(min(dists))\n",
    "        return index\n",
    "        \n",
    "    def predict(self, df):\n",
    "        res = []\n",
    "        for row in df.values:\n",
    "            res.append(self.predict_row(row))\n",
    "        return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = MyKmeans(5, max_iter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Error: 7.150260905418475\n",
      "Iteration: 1\n",
      "Error: 4.619416814852405\n",
      "Iteration: 2\n",
      "Error: 2.2565456857018034\n",
      "Iteration: 3\n",
      "Error: 1.512878408931828\n",
      "Iteration: 4\n",
      "Error: 0.6254204067285118\n",
      "Iteration: 5\n",
      "Error: 0.28570662387104845\n",
      "Iteration: 6\n",
      "Error: 0.3137070544295438\n",
      "Iteration: 7\n",
      "Error: 1.1419347868436565\n",
      "Iteration: 8\n",
      "Error: 1.2230229908669894\n",
      "Iteration: 9\n",
      "Error: 0.23885433664926758\n",
      "Iteration: 10\n",
      "Error: 0.08544597215705149\n",
      "Iteration: 11\n",
      "Error: 0.03209990647350283\n",
      "Iteration: 12\n",
      "Error: 0.00921581901433813\n",
      "Iteration: 13\n",
      "Error: 0.005064863258115755\n",
      "Iteration: 14\n",
      "Error: 0.002147084425612644\n",
      "Iteration: 15\n",
      "Error: 0.0\n"
     ]
    }
   ],
   "source": [
    "kmeans.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_pred = kmeans.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 0, ..., 0, 1, 2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'normal', 1: 'normal', 2: 'dos', 3: 'dos', 4: 'normal'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 'normal', 1: 'normal', 2: 'dos', 3: 'dos', 4: 'normal'},\n",
       " {0: 0.915825208913649,\n",
       "  1: 0.530448717948718,\n",
       "  2: 0.9839525805985254,\n",
       "  3: 0.4623728813559322,\n",
       "  4: 0.730660643704122})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcPurity(5, kmeans_pred, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn K means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans1 = KMeans(n_clusters=5, random_state=0).fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_kmeans_pred = kmeans1.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 'probe', 1: 'normal', 2: 'dos', 3: 'dos', 4: 'normal'},\n",
       " {0: 0.8070866141732284,\n",
       "  1: 0.8974595515185921,\n",
       "  2: 0.9838126896950427,\n",
       "  3: 0.4603442456969288,\n",
       "  4: 1.0})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcPurity(5, sk_kmeans_pred, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART - 3 GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.misc import imread, imshow\n",
    "from sklearn import mixture\n",
    "gmm = mixture.GaussianMixture(covariance_type='full', n_components=5)\n",
    "gmm.fit(X_train)\n",
    "gmm_pred = gmm.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 0 4 ... 3 4 1]\n"
     ]
    }
   ],
   "source": [
    "print(gmm_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 'normal', 1: 'dos', 2: 'normal', 3: 'normal', 4: 'normal'},\n",
       " {0: 0.49483985765124555,\n",
       "  1: 1.0,\n",
       "  2: 1.0,\n",
       "  3: 0.4834193072955048,\n",
       "  4: 0.8628218510786361})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcPurity(5, gmm_pred, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART - 4 Hierarchical clustering with single-linkage and five clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "cluster = AgglomerativeClustering(n_clusters=5, affinity='euclidean', linkage='single')  \n",
    "hclust_pred = cluster.fit_predict(X_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 'normal', 1: 'probe', 2: 'r2l', 3: 'normal', 4: 'normal'},\n",
       " {0: 0.5346352395053824, 1: 1.0, 2: 0.6666666666666666, 3: 1.0, 4: 1.0})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcPurity(5, hclust_pred, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pie Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_types = {\"kmeans\" : kmeans_pred, \"gmm\" : gmm_pred, \"hclust\" : hclust_pred}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_index = 0\n",
    "for cluster_type, y_pred in cluster_types.items():\n",
    "    labels, purity = calcPurity(5, y_pred, y_train)\n",
    "    labels = [\"cluster_\" + str(k) + \"_\" + val for k, val in labels.items()]\n",
    "    sizes = [val for k, val in purity.items()]\n",
    "    # print(sizes) # adds up to 1433, which is the total number of participants\n",
    "    ax1 = plt.subplot(2,2,plot_index+1)\n",
    "    ax1.figure.set_size_inches(6, 8)\n",
    "    ax1.pie(sizes, labels=labels, autopct='%1.1f%%', shadow=True)\n",
    "    ax1.axis('equal')\n",
    "    ax1.set_title(str(cluster_type))\n",
    "    plot_index += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_orig_df = pd.read_csv(\"AdmissionDataset/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>242</td>\n",
       "      <td>317</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>334</td>\n",
       "      <td>319</td>\n",
       "      <td>108</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.54</td>\n",
       "      <td>1</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>326</td>\n",
       "      <td>113</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>232</td>\n",
       "      <td>319</td>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.33</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0         242        317          103                  2  2.5   2.0  8.15   \n",
       "1         334        319          108                  3  3.0   3.5  8.54   \n",
       "2           4        322          110                  3  3.5   2.5  8.67   \n",
       "3          45        326          113                  5  4.5   4.0  9.40   \n",
       "4         232        319          106                  3  3.5   2.5  8.33   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         0              0.65  \n",
       "1         1              0.71  \n",
       "2         1              0.80  \n",
       "3         1              0.91  \n",
       "4         1              0.74  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admission_orig_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>247.726667</td>\n",
       "      <td>316.542222</td>\n",
       "      <td>107.162222</td>\n",
       "      <td>3.126667</td>\n",
       "      <td>3.361111</td>\n",
       "      <td>3.468889</td>\n",
       "      <td>8.577600</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.720889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>144.927656</td>\n",
       "      <td>11.335705</td>\n",
       "      <td>6.023554</td>\n",
       "      <td>1.140254</td>\n",
       "      <td>0.993374</td>\n",
       "      <td>0.919432</td>\n",
       "      <td>0.599454</td>\n",
       "      <td>0.497701</td>\n",
       "      <td>0.141398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>124.250000</td>\n",
       "      <td>308.250000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.122500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>246.500000</td>\n",
       "      <td>317.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>8.560000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>373.750000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.040000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.920000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Serial No.   GRE Score  TOEFL Score  University Rating         SOP  \\\n",
       "count  450.000000  450.000000   450.000000         450.000000  450.000000   \n",
       "mean   247.726667  316.542222   107.162222           3.126667    3.361111   \n",
       "std    144.927656   11.335705     6.023554           1.140254    0.993374   \n",
       "min      1.000000  290.000000    92.000000           1.000000    1.000000   \n",
       "25%    124.250000  308.250000   103.000000           2.000000    2.500000   \n",
       "50%    246.500000  317.000000   107.000000           3.000000    3.500000   \n",
       "75%    373.750000  325.000000   112.000000           4.000000    4.000000   \n",
       "max    500.000000  340.000000   120.000000           5.000000    5.000000   \n",
       "\n",
       "             LOR         CGPA    Research  Chance of Admit   \n",
       "count  450.000000  450.000000  450.000000        450.000000  \n",
       "mean     3.468889    8.577600    0.553333          0.720889  \n",
       "std      0.919432    0.599454    0.497701          0.141398  \n",
       "min      1.000000    7.200000    0.000000          0.340000  \n",
       "25%      3.000000    8.122500    0.000000          0.630000  \n",
       "50%      3.500000    8.560000    1.000000          0.720000  \n",
       "75%      4.000000    9.040000    1.000000          0.820000  \n",
       "max      5.000000    9.920000    1.000000          0.970000  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admission_orig_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_orig_cols = ['Serial_No', 'GRE_Score', 'TOEFL_Score', 'University_Rating', 'SOP', 'LOR', 'CGPA', 'Research', 'Chance_of_Admit']\n",
    "admission_orig_df.columns = admission_orig_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial_No</th>\n",
       "      <th>GRE_Score</th>\n",
       "      <th>TOEFL_Score</th>\n",
       "      <th>University_Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance_of_Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>242</td>\n",
       "      <td>317</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>334</td>\n",
       "      <td>319</td>\n",
       "      <td>108</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.54</td>\n",
       "      <td>1</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>326</td>\n",
       "      <td>113</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>232</td>\n",
       "      <td>319</td>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.33</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial_No  GRE_Score  TOEFL_Score  University_Rating  SOP  LOR  CGPA  \\\n",
       "0        242        317          103                  2  2.5  2.0  8.15   \n",
       "1        334        319          108                  3  3.0  3.5  8.54   \n",
       "2          4        322          110                  3  3.5  2.5  8.67   \n",
       "3         45        326          113                  5  4.5  4.0  9.40   \n",
       "4        232        319          106                  3  3.5  2.5  8.33   \n",
       "\n",
       "   Research  Chance_of_Admit  \n",
       "0         0             0.65  \n",
       "1         1             0.71  \n",
       "2         1             0.80  \n",
       "3         1             0.91  \n",
       "4         1             0.74  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admission_orig_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial_No</th>\n",
       "      <th>GRE_Score</th>\n",
       "      <th>TOEFL_Score</th>\n",
       "      <th>University_Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance_of_Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Serial_No, GRE_Score, TOEFL_Score, University_Rating, SOP, LOR, CGPA, Research, Chance_of_Admit]\n",
       "Index: []"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admission_orig_df[admission_orig_df['GRE_Score'] != admission_orig_df.GRE_Score.astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial_No</th>\n",
       "      <th>GRE_Score</th>\n",
       "      <th>TOEFL_Score</th>\n",
       "      <th>University_Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance_of_Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Serial_No</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.080196</td>\n",
       "      <td>-0.115323</td>\n",
       "      <td>-0.027499</td>\n",
       "      <td>-0.108152</td>\n",
       "      <td>0.010717</td>\n",
       "      <td>-0.061309</td>\n",
       "      <td>0.010068</td>\n",
       "      <td>0.023551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRE_Score</th>\n",
       "      <td>-0.080196</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.821423</td>\n",
       "      <td>0.631178</td>\n",
       "      <td>0.616670</td>\n",
       "      <td>0.535315</td>\n",
       "      <td>0.826544</td>\n",
       "      <td>0.562533</td>\n",
       "      <td>0.810894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOEFL_Score</th>\n",
       "      <td>-0.115323</td>\n",
       "      <td>0.821423</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.642612</td>\n",
       "      <td>0.648256</td>\n",
       "      <td>0.544411</td>\n",
       "      <td>0.810381</td>\n",
       "      <td>0.471452</td>\n",
       "      <td>0.790005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>University_Rating</th>\n",
       "      <td>-0.027499</td>\n",
       "      <td>0.631178</td>\n",
       "      <td>0.642612</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.722434</td>\n",
       "      <td>0.614527</td>\n",
       "      <td>0.696721</td>\n",
       "      <td>0.437424</td>\n",
       "      <td>0.685563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOP</th>\n",
       "      <td>-0.108152</td>\n",
       "      <td>0.616670</td>\n",
       "      <td>0.648256</td>\n",
       "      <td>0.722434</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.664015</td>\n",
       "      <td>0.713633</td>\n",
       "      <td>0.403552</td>\n",
       "      <td>0.681585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOR</th>\n",
       "      <td>0.010717</td>\n",
       "      <td>0.535315</td>\n",
       "      <td>0.544411</td>\n",
       "      <td>0.614527</td>\n",
       "      <td>0.664015</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.640347</td>\n",
       "      <td>0.392998</td>\n",
       "      <td>0.644693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CGPA</th>\n",
       "      <td>-0.061309</td>\n",
       "      <td>0.826544</td>\n",
       "      <td>0.810381</td>\n",
       "      <td>0.696721</td>\n",
       "      <td>0.713633</td>\n",
       "      <td>0.640347</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.507005</td>\n",
       "      <td>0.877802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Research</th>\n",
       "      <td>0.010068</td>\n",
       "      <td>0.562533</td>\n",
       "      <td>0.471452</td>\n",
       "      <td>0.437424</td>\n",
       "      <td>0.403552</td>\n",
       "      <td>0.392998</td>\n",
       "      <td>0.507005</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.557906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chance_of_Admit</th>\n",
       "      <td>0.023551</td>\n",
       "      <td>0.810894</td>\n",
       "      <td>0.790005</td>\n",
       "      <td>0.685563</td>\n",
       "      <td>0.681585</td>\n",
       "      <td>0.644693</td>\n",
       "      <td>0.877802</td>\n",
       "      <td>0.557906</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Serial_No  GRE_Score  TOEFL_Score  University_Rating  \\\n",
       "Serial_No           1.000000  -0.080196    -0.115323          -0.027499   \n",
       "GRE_Score          -0.080196   1.000000     0.821423           0.631178   \n",
       "TOEFL_Score        -0.115323   0.821423     1.000000           0.642612   \n",
       "University_Rating  -0.027499   0.631178     0.642612           1.000000   \n",
       "SOP                -0.108152   0.616670     0.648256           0.722434   \n",
       "LOR                 0.010717   0.535315     0.544411           0.614527   \n",
       "CGPA               -0.061309   0.826544     0.810381           0.696721   \n",
       "Research            0.010068   0.562533     0.471452           0.437424   \n",
       "Chance_of_Admit     0.023551   0.810894     0.790005           0.685563   \n",
       "\n",
       "                        SOP       LOR      CGPA  Research  Chance_of_Admit  \n",
       "Serial_No         -0.108152  0.010717 -0.061309  0.010068         0.023551  \n",
       "GRE_Score          0.616670  0.535315  0.826544  0.562533         0.810894  \n",
       "TOEFL_Score        0.648256  0.544411  0.810381  0.471452         0.790005  \n",
       "University_Rating  0.722434  0.614527  0.696721  0.437424         0.685563  \n",
       "SOP                1.000000  0.664015  0.713633  0.403552         0.681585  \n",
       "LOR                0.664015  1.000000  0.640347  0.392998         0.644693  \n",
       "CGPA               0.713633  0.640347  1.000000  0.507005         0.877802  \n",
       "Research           0.403552  0.392998  0.507005  1.000000         0.557906  \n",
       "Chance_of_Admit    0.681585  0.644693  0.877802  0.557906         1.000000  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = admission_orig_df.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Serial Number\n",
    "admission_df = admission_orig_df.drop(columns=['Serial_No'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE_Score</th>\n",
       "      <th>TOEFL_Score</th>\n",
       "      <th>University_Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance_of_Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GRE_Score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.821423</td>\n",
       "      <td>0.631178</td>\n",
       "      <td>0.616670</td>\n",
       "      <td>0.535315</td>\n",
       "      <td>0.826544</td>\n",
       "      <td>0.562533</td>\n",
       "      <td>0.810894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOEFL_Score</th>\n",
       "      <td>0.821423</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.642612</td>\n",
       "      <td>0.648256</td>\n",
       "      <td>0.544411</td>\n",
       "      <td>0.810381</td>\n",
       "      <td>0.471452</td>\n",
       "      <td>0.790005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>University_Rating</th>\n",
       "      <td>0.631178</td>\n",
       "      <td>0.642612</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.722434</td>\n",
       "      <td>0.614527</td>\n",
       "      <td>0.696721</td>\n",
       "      <td>0.437424</td>\n",
       "      <td>0.685563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOP</th>\n",
       "      <td>0.616670</td>\n",
       "      <td>0.648256</td>\n",
       "      <td>0.722434</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.664015</td>\n",
       "      <td>0.713633</td>\n",
       "      <td>0.403552</td>\n",
       "      <td>0.681585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOR</th>\n",
       "      <td>0.535315</td>\n",
       "      <td>0.544411</td>\n",
       "      <td>0.614527</td>\n",
       "      <td>0.664015</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.640347</td>\n",
       "      <td>0.392998</td>\n",
       "      <td>0.644693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CGPA</th>\n",
       "      <td>0.826544</td>\n",
       "      <td>0.810381</td>\n",
       "      <td>0.696721</td>\n",
       "      <td>0.713633</td>\n",
       "      <td>0.640347</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.507005</td>\n",
       "      <td>0.877802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Research</th>\n",
       "      <td>0.562533</td>\n",
       "      <td>0.471452</td>\n",
       "      <td>0.437424</td>\n",
       "      <td>0.403552</td>\n",
       "      <td>0.392998</td>\n",
       "      <td>0.507005</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.557906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chance_of_Admit</th>\n",
       "      <td>0.810894</td>\n",
       "      <td>0.790005</td>\n",
       "      <td>0.685563</td>\n",
       "      <td>0.681585</td>\n",
       "      <td>0.644693</td>\n",
       "      <td>0.877802</td>\n",
       "      <td>0.557906</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   GRE_Score  TOEFL_Score  University_Rating       SOP  \\\n",
       "GRE_Score           1.000000     0.821423           0.631178  0.616670   \n",
       "TOEFL_Score         0.821423     1.000000           0.642612  0.648256   \n",
       "University_Rating   0.631178     0.642612           1.000000  0.722434   \n",
       "SOP                 0.616670     0.648256           0.722434  1.000000   \n",
       "LOR                 0.535315     0.544411           0.614527  0.664015   \n",
       "CGPA                0.826544     0.810381           0.696721  0.713633   \n",
       "Research            0.562533     0.471452           0.437424  0.403552   \n",
       "Chance_of_Admit     0.810894     0.790005           0.685563  0.681585   \n",
       "\n",
       "                        LOR      CGPA  Research  Chance_of_Admit  \n",
       "GRE_Score          0.535315  0.826544  0.562533         0.810894  \n",
       "TOEFL_Score        0.544411  0.810381  0.471452         0.790005  \n",
       "University_Rating  0.614527  0.696721  0.437424         0.685563  \n",
       "SOP                0.664015  0.713633  0.403552         0.681585  \n",
       "LOR                1.000000  0.640347  0.392998         0.644693  \n",
       "CGPA               0.640347  1.000000  0.507005         0.877802  \n",
       "Research           0.392998  0.507005  1.000000         0.557906  \n",
       "Chance_of_Admit    0.644693  0.877802  0.557906         1.000000  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = admission_df.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6af9c1d7f0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the heatmap\n",
    "sns.heatmap(corr, \n",
    "        xticklabels=corr.columns,\n",
    "        yticklabels=corr.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#admission_df.iloc[:,admission_df.columns != 'Chance_of_Admit'] = (admission_df.iloc[:,admission_df.columns != 'Chance_of_Admit'] - admission_df.iloc[:,admission_df.columns != 'Chance_of_Admit'].mean())/admission_df.iloc[:,admission_df.columns != 'Chance_of_Admit'].std()\n",
    "# admission_df = (admission_df - admission_df.mean())/admission_df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE_Score</th>\n",
       "      <th>TOEFL_Score</th>\n",
       "      <th>University_Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance_of_Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>316.542222</td>\n",
       "      <td>107.162222</td>\n",
       "      <td>3.126667</td>\n",
       "      <td>3.361111</td>\n",
       "      <td>3.468889</td>\n",
       "      <td>8.577600</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.720889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.335705</td>\n",
       "      <td>6.023554</td>\n",
       "      <td>1.140254</td>\n",
       "      <td>0.993374</td>\n",
       "      <td>0.919432</td>\n",
       "      <td>0.599454</td>\n",
       "      <td>0.497701</td>\n",
       "      <td>0.141398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>290.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>308.250000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.122500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>317.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>8.560000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>325.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.040000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>340.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.920000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        GRE_Score  TOEFL_Score  University_Rating         SOP         LOR  \\\n",
       "count  450.000000   450.000000         450.000000  450.000000  450.000000   \n",
       "mean   316.542222   107.162222           3.126667    3.361111    3.468889   \n",
       "std     11.335705     6.023554           1.140254    0.993374    0.919432   \n",
       "min    290.000000    92.000000           1.000000    1.000000    1.000000   \n",
       "25%    308.250000   103.000000           2.000000    2.500000    3.000000   \n",
       "50%    317.000000   107.000000           3.000000    3.500000    3.500000   \n",
       "75%    325.000000   112.000000           4.000000    4.000000    4.000000   \n",
       "max    340.000000   120.000000           5.000000    5.000000    5.000000   \n",
       "\n",
       "             CGPA    Research  Chance_of_Admit  \n",
       "count  450.000000  450.000000       450.000000  \n",
       "mean     8.577600    0.553333         0.720889  \n",
       "std      0.599454    0.497701         0.141398  \n",
       "min      7.200000    0.000000         0.340000  \n",
       "25%      8.122500    0.000000         0.630000  \n",
       "50%      8.560000    1.000000         0.720000  \n",
       "75%      9.040000    1.000000         0.820000  \n",
       "max      9.920000    1.000000         0.970000  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admission_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data into train(80%) and validation(20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_train_X, admission_val_X, admission_train_Y, admission_val_Y = splitData(admission_df.iloc[:,admission_df.columns != 'Chance_of_Admit'], admission_df['Chance_of_Admit'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean(row1, row2):\n",
    "    if(len(row1) != len(row2)):\n",
    "        raise ValueError('row lengths do not match in euclidean dist calculation!')\n",
    "    return np.sqrt(np.sum([(x-y)**2 for x, y in zip(row1,row2)]))\n",
    "\n",
    "def chebyshev(row1, row2):\n",
    "    if(len(row1) != len(row2)):\n",
    "        raise ValueError('row lengths do not match in chebyshev dist calculation!')\n",
    "    return np.max([abs(x-y) for x, y in zip(row1,row2)])\n",
    "\n",
    "def manhattan(row1, row2):\n",
    "    if(len(row1) != len(row2)):\n",
    "        raise ValueError('row lengths do not match in manhattan dist calculation!')\n",
    "    return np.sum([abs(x-y) for x, y in zip(row1,row2)])\n",
    "\n",
    "def minkowski(row1, row2):\n",
    "    if(len(row1) != len(row2)):\n",
    "        raise ValueError('row lengths do not match in minkowski dist calculation!')\n",
    "    x = np.cbrt(np.sum([abs(x-y)**3 for x, y in zip(row1,row2)]))\n",
    "#     print(x)\n",
    "    return x\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def printRegressionErrors(y, y_pred):\n",
    "    mse = metrics.mean_squared_error(sigmoid(admission_val_Y), y_pred)  \n",
    "    mae = metrics.mean_absolute_error(sigmoid(admission_val_Y), y_pred)\n",
    "    mape = mean_absolute_percentage_error(sigmoid(admission_val_Y), y_pred)\n",
    "    print(\"MSE : {0}\".format(mse))\n",
    "    print(\"MAE : {0}\".format(mae))\n",
    "    print(\"MAPE : {0}\".format(mape))\n",
    "    \n",
    "def makeCoeffDF(coeffs):\n",
    "    coeff_cols = ['GRE_Score', 'TOEFL_Score', \n",
    "                  'University_Rating', 'SOP', 'LOR', 'CGPA', 'Research', 'Intercept']\n",
    "    coeff_df = pd.DataFrame(coeffs, columns=coeff_cols)\n",
    "    return coeff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(Y_predict, Y_test):\n",
    "    accuracy = metrics.accuracy_score(Y_test, Y_predict)\n",
    "    precision = metrics.precision_score(Y_test, Y_predict, pos_label=1, average='macro')\n",
    "    recall = metrics.recall_score(Y_test, Y_predict,pos_label=1, average='macro')\n",
    "    f1_score = metrics.f1_score(Y_test, Y_predict,pos_label=1, average='macro')\n",
    "    print(\"Accuracy : \" +str(accuracy))\n",
    "    print(\"Precision : \" +str(precision))\n",
    "    print(\"recall : \" +str(recall))\n",
    "    print(\"f1 Score : \" +str(f1_score))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(Y_predict, Y_test):\n",
    "    accuracy = metrics.accuracy_score(Y_test, Y_predict)\n",
    "    precision = metrics.precision_score(Y_test, Y_predict, pos_label=1, average='macro')\n",
    "    recall = metrics.recall_score(Y_test, Y_predict,pos_label=1, average='macro')\n",
    "    f1_score = metrics.f1_score(Y_test, Y_predict,pos_label=1, average='macro')\n",
    "    return [accuracy, precision, recall, f1_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating metrics for all datasets\n",
    "def evaluate_metric_dataframe(datasets1, model):\n",
    "    metric_cols = ['DataSet', 'Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "    metric_df = pd.DataFrame(columns = metric_cols)\n",
    "    for data in datasets1:\n",
    "        model.fit(data[1], data[2])\n",
    "        pred_Y = model.predict(data[3])\n",
    "        scores = calc_metrics(pred_Y, data[4])\n",
    "        metric_df = metric_df.append(pd.DataFrame([[data[0]] + scores], columns=metric_cols),ignore_index=True)\n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    def __init__(self, n_neighbors=5, metric=euclidean):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.metric = metric\n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        self.scaler = MinMaxScaler()\n",
    "        self.scaler = self.scaler.fit(X)\n",
    "        self.train_X = pd.DataFrame(self.scaler.transform(X), columns=X.columns)\n",
    "#         self.train_X = X\n",
    "        self.train_Y = Y\n",
    "\n",
    "    def scalerFit(self, df):\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(df)\n",
    "        return scaler\n",
    "\n",
    "    def transform(self, scalar, df, cols):\n",
    "        df_scaled = pd.DataFrame(scaler.transform(df[cols]), columns=cols)\n",
    "        return df_scaled\n",
    "\n",
    "    def predict_row(self, row):\n",
    "        dists = []\n",
    "        index = 0\n",
    "        for i, train_row in self.train_X.iterrows():\n",
    "            dist = self.metric(row, train_row)\n",
    "            label = self.train_Y.iloc[index]\n",
    "            dists.append((dist,label))\n",
    "            index += 1\n",
    "        dists.sort()\n",
    "        dists = dists[:self.n_neighbors]\n",
    "        elem,count = np.unique([j for (i,j) in dists], return_counts=True)\n",
    "        return elem[np.argmax(count)]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = pd.DataFrame(self.scaler.transform(X), columns=X.columns)\n",
    "        y = []\n",
    "        for index, row in X.iterrows():\n",
    "            y.append(self.predict_row(row))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART - 1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_df_log = admission_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE_Score</th>\n",
       "      <th>TOEFL_Score</th>\n",
       "      <th>University_Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance_of_Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>317</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>319</td>\n",
       "      <td>108</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.54</td>\n",
       "      <td>1</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>326</td>\n",
       "      <td>113</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>319</td>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.33</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE_Score  TOEFL_Score  University_Rating  SOP  LOR  CGPA  Research  \\\n",
       "0        317          103                  2  2.5  2.0  8.15         0   \n",
       "1        319          108                  3  3.0  3.5  8.54         1   \n",
       "2        322          110                  3  3.5  2.5  8.67         1   \n",
       "3        326          113                  5  4.5  4.0  9.40         1   \n",
       "4        319          106                  3  3.5  2.5  8.33         1   \n",
       "\n",
       "   Chance_of_Admit  \n",
       "0             0.65  \n",
       "1             0.71  \n",
       "2             0.80  \n",
       "3             0.91  \n",
       "4             0.74  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admission_df_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_df_log['Chance_of_Admit'] = [1 if x >= 0.5 else 0 for x in admission_df['Chance_of_Admit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE_Score</th>\n",
       "      <th>TOEFL_Score</th>\n",
       "      <th>University_Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance_of_Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>450.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>316.542222</td>\n",
       "      <td>107.162222</td>\n",
       "      <td>3.126667</td>\n",
       "      <td>3.361111</td>\n",
       "      <td>3.468889</td>\n",
       "      <td>8.577600</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.922222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.335705</td>\n",
       "      <td>6.023554</td>\n",
       "      <td>1.140254</td>\n",
       "      <td>0.993374</td>\n",
       "      <td>0.919432</td>\n",
       "      <td>0.599454</td>\n",
       "      <td>0.497701</td>\n",
       "      <td>0.268120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>290.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>308.250000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.122500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>317.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>8.560000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>325.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.040000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>340.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.920000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        GRE_Score  TOEFL_Score  University_Rating         SOP         LOR  \\\n",
       "count  450.000000   450.000000         450.000000  450.000000  450.000000   \n",
       "mean   316.542222   107.162222           3.126667    3.361111    3.468889   \n",
       "std     11.335705     6.023554           1.140254    0.993374    0.919432   \n",
       "min    290.000000    92.000000           1.000000    1.000000    1.000000   \n",
       "25%    308.250000   103.000000           2.000000    2.500000    3.000000   \n",
       "50%    317.000000   107.000000           3.000000    3.500000    3.500000   \n",
       "75%    325.000000   112.000000           4.000000    4.000000    4.000000   \n",
       "max    340.000000   120.000000           5.000000    5.000000    5.000000   \n",
       "\n",
       "             CGPA    Research  Chance_of_Admit  \n",
       "count  450.000000  450.000000       450.000000  \n",
       "mean     8.577600    0.553333         0.922222  \n",
       "std      0.599454    0.497701         0.268120  \n",
       "min      7.200000    0.000000         0.000000  \n",
       "25%      8.122500    0.000000         1.000000  \n",
       "50%      8.560000    1.000000         1.000000  \n",
       "75%      9.040000    1.000000         1.000000  \n",
       "max      9.920000    1.000000         1.000000  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admission_df_log.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_train_X, admission_val_X, admission_train_Y, admission_val_Y = splitData(admission_df_log.iloc[:,admission_df_log.columns != 'Chance_of_Admit'], admission_df_log['Chance_of_Admit'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLogisticRegresson:\n",
    "    def __init__(self, learning_rate = 0.01, no_iterations = 1000 ,threshold = 0.5):\n",
    "        self.alpha = learning_rate\n",
    "        self.iterations = no_iterations\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def normalize_X(self, X):\n",
    "        X_normalized = (X - self.X_mean)/self.X_var\n",
    "        return X_normalized\n",
    "\n",
    "    def normalize_Y(self, Y):\n",
    "#         return X\n",
    "        Y_normalized = (Y - self.Y_mean)/self.Y_var\n",
    "        return Y_normalized\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        #### m = no of examples, n = no of features\n",
    "        ### X : shape = mxn\n",
    "        ### Y : shape = 1xm\n",
    "        self.X_mean = X.mean()\n",
    "#         print(\"mean: {0}\",self.X_mean)\n",
    "        self.X_var = X.std()\n",
    "        self.Y_mean = Y.mean()\n",
    "        self.Y_var = Y.std()\n",
    "        \n",
    "        X  = self.normalize_X(X)\n",
    "#         Y  = self.normalize_Y(Y)\n",
    "        c = np.ones((1, len(X)))  ### shape = 1xm\n",
    "        X_temp = np.concatenate((X, c.T), axis=1) ## Shape : mxn\n",
    "        theta = np.zeros((1, len(X_temp[0]))) ## shape: 1 X n \n",
    "        Y_temp = Y.values.reshape(len(X),1)  ## shape : (m,1)\n",
    "#         print(X_temp)\n",
    "#         print(\"X : {0}, theta : {1}, Y : {2}\".format(X_temp.shape, theta.shape, Y_temp.shape))\n",
    "        theta, cost_hist = self.gradient_descent(theta, X_temp, Y_temp, self.alpha, self.iterations)\n",
    "        self.theta = theta\n",
    "        self.coef_ = theta.flatten()[:-1]\n",
    "        self.cost_hist = cost_hist\n",
    "        self.intercept_ = theta.flatten()[-1:]\n",
    "#         print(theta)\n",
    "    \n",
    "    def predict_probs(self, X):\n",
    "        X = self.normalize_X(X)\n",
    "        c = np.ones((1, len(X)))  ### shape = 1xm\n",
    "        X_temp = np.concatenate((X, c.T), axis=1) ## Shape : kxn\n",
    "        y_pred = np.dot(X_temp,self.theta.T)\n",
    "        return sigmoid(y_pred.flatten())\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_probs = self.predict_probs(X)\n",
    "        y_probs[y_probs >= self.threshold] = 1\n",
    "        y_probs[y_probs < self.threshold] = 0\n",
    "        return y_probs\n",
    "    \n",
    "    def allCoeffs(self):\n",
    "        coeffs = list(self.coef_) + list(self.intercept_)\n",
    "        coeffs = np.array(coeffs).reshape(1, len(coeffs))\n",
    "        return coeffs\n",
    "    \n",
    "    def __loss(self, Y, h):\n",
    "        h1 = h.copy()\n",
    "        h1[h1 == 0] = 1\n",
    "        h2 = h.copy()\n",
    "        h2[h2 == 1] = 0\n",
    "        return np.mean(-Y * np.log(h1) - (1 - Y) * np.log(1 - h2))\n",
    "        \n",
    "    def gradient_descent(self, theta, X, Y, alpha, iterations):\n",
    "        cost_history = [0] * iterations\n",
    "        m = len(Y)\n",
    "\n",
    "        for iteration in range(iterations):\n",
    "            # Hypothesis Values\n",
    "#             print(theta)\n",
    "#             print(X.shape, theta.T.shape)\n",
    "            zz = np.dot(X,theta.T)\n",
    "#             print(zz)\n",
    "            h = sigmoid(zz) ## shape : (m,1)\n",
    "            \n",
    "            loss = h - Y ## shape: (m,1)\n",
    "#             print(\"loss: {0}\".format(loss.shape))\n",
    "#             print(\"loss : {0}\".format(np.sum(loss)))\n",
    "            # Gradient Calculation\n",
    "            gradient = np.dot(X.T,loss) / m   ##shape : (n,1)\n",
    "#             print(\"grad: {0}\".format(gradient.shape))\n",
    "            # Changing Values of B using Gradient\n",
    "            theta = theta - alpha * (gradient.T)\n",
    "#             print(theta.shape)\n",
    "            # New Cost Value\n",
    "            cost = self.__loss(Y, h)\n",
    "            cost_history[iteration] = cost\n",
    "#             print(\"i: {0}\".format(iteration), sep=\" \")\n",
    "#             print(\"theta: {0}\".format(theta), sep= \" \")\n",
    "#             print(\"cost: {0}\".format(cost))\n",
    "#             print(cost, theta)\n",
    "        \n",
    "#         ax = plt.subplot(1,1,1)\n",
    "#         ax.plot(range(iterations), cost_history)\n",
    "#         ax.set_xlabel('iteration')\n",
    "#         ax.set_ylabel('cost')\n",
    "#         plt.show()\n",
    "\n",
    "        return theta, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "lr = MyLogisticRegresson(0.01, 10000)\n",
    "lr.fit(admission_train_X,admission_train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lr.predict(admission_val_X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE_Score</th>\n",
       "      <th>TOEFL_Score</th>\n",
       "      <th>University_Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Intercept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.441141</td>\n",
       "      <td>0.754185</td>\n",
       "      <td>-0.255086</td>\n",
       "      <td>-0.467181</td>\n",
       "      <td>0.481577</td>\n",
       "      <td>1.356643</td>\n",
       "      <td>0.045651</td>\n",
       "      <td>3.947705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE_Score  TOEFL_Score  University_Rating       SOP       LOR      CGPA  \\\n",
       "0   0.441141     0.754185          -0.255086 -0.467181  0.481577  1.356643   \n",
       "\n",
       "   Research  Intercept  \n",
       "0  0.045651   3.947705  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "makeCoeffDF(lr.allCoeffs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9555555555555556"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(admission_val_Y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[[-0.08908858  0.11668916  0.05232433 -0.2544266   0.75885504  2.04799802\n",
      "   0.6798165 ]]\n",
      "[-0.61218553]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8888888888888888"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(admission_train_X, admission_train_Y)\n",
    "y_pred = clf.predict(admission_val_X)\n",
    "print(y_pred)\n",
    "print(clf.coef_)\n",
    "print(clf.intercept_)\n",
    "metrics.accuracy_score(admission_val_Y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE_Score</th>\n",
       "      <th>TOEFL_Score</th>\n",
       "      <th>University_Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>327</td>\n",
       "      <td>111</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>320</td>\n",
       "      <td>110</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>320</td>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.78</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>309</td>\n",
       "      <td>105</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>338</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE_Score  TOEFL_Score  University_Rating  SOP  LOR  CGPA  Research\n",
       "66         327          111                  4  3.0  4.0  8.40         1\n",
       "309        320          110                  5  5.0  4.5  9.22         1\n",
       "312        320          112                  2  3.5  3.5  8.78         1\n",
       "12         309          105                  4  3.5  2.0  8.18         0\n",
       "219        338          118                  4  3.0  4.5  9.40         1"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admission_train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "myKNN = KNN(n_neighbors=5, metric=euclidean)\n",
    "myKNN.fit(admission_train_X, admission_train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = myKNN.predict(admission_val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9111111111111111"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(admission_val_Y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1080 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "precisions = []\n",
    "recalls = []\n",
    "thresholds = [i/50 for i in range(0,50)]\n",
    "for threshold in thresholds:\n",
    "    lr = MyLogisticRegresson(0.1, 500, threshold)\n",
    "    lr.fit(admission_train_X,admission_train_Y)  \n",
    "    y_pred = lr.predict(admission_val_X)\n",
    "    precisions.append(metrics.precision_score(y_pred=y_pred, y_true=admission_val_Y))\n",
    "    recalls.append(metrics.recall_score(y_pred=y_pred, y_true=admission_val_Y))\n",
    "    \n",
    "ax = plt.subplot(2, 1, 1)\n",
    "# plt.style.use('seaborn-darkgrid')\n",
    "ax.figure.set_size_inches(10,15)\n",
    "\n",
    "# create a color palette\n",
    "palette = plt.get_cmap('Set1')\n",
    "ax.plot(thresholds, precisions, marker='', color=palette(0), linewidth=1, alpha=0.9, label='precision')\n",
    "ax.plot(thresholds, recalls, marker='', color=palette(1), linewidth=1, alpha=0.9, label='recall')\n",
    "\n",
    "# Add legend\n",
    "ax.legend(loc=2, ncol=2)\n",
    "\n",
    "# Add titles\n",
    "# ax.set_title(\"Precision and Recall variation\", loc='left', fontsize=12, fontweight=0, color='orange')\n",
    "ax.set_xlabel('threshold')\n",
    "ax.set_ylabel('metrics')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 0.9101123595505618,\n",
       " 0.9101123595505618,\n",
       " 0.9101123595505618,\n",
       " 0.9101123595505618,\n",
       " 0.9101123595505618,\n",
       " 0.9204545454545454,\n",
       " 0.9418604651162791,\n",
       " 0.9529411764705882,\n",
       " 0.9529411764705882,\n",
       " 0.9642857142857143,\n",
       " 0.9642857142857143,\n",
       " 0.9642857142857143,\n",
       " 0.9634146341463414,\n",
       " 0.9634146341463414,\n",
       " 0.9634146341463414,\n",
       " 0.9634146341463414,\n",
       " 0.9629629629629629,\n",
       " 0.9629629629629629,\n",
       " 0.9620253164556962,\n",
       " 0.961038961038961,\n",
       " 0.961038961038961,\n",
       " 0.9605263157894737,\n",
       " 0.9583333333333334,\n",
       " 0.9577464788732394,\n",
       " 0.9571428571428572,\n",
       " 0.9552238805970149,\n",
       " 0.96875,\n",
       " 0.9827586206896551,\n",
       " 0.9803921568627451,\n",
       " 1.0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9753086419753086,\n",
       " 0.9753086419753086,\n",
       " 0.9753086419753086,\n",
       " 0.9753086419753086,\n",
       " 0.9629629629629629,\n",
       " 0.9629629629629629,\n",
       " 0.9382716049382716,\n",
       " 0.9135802469135802,\n",
       " 0.9135802469135802,\n",
       " 0.9012345679012346,\n",
       " 0.8518518518518519,\n",
       " 0.8395061728395061,\n",
       " 0.8271604938271605,\n",
       " 0.7901234567901234,\n",
       " 0.7654320987654321,\n",
       " 0.7037037037037037,\n",
       " 0.6172839506172839,\n",
       " 0.4444444444444444]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(precisions)\n",
    "display(recalls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question - 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df_orig = pd.read_csv(\"./wine-quality/data_changed.csv\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One vs All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.026</td>\n",
       "      <td>31.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.99160</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0.37</td>\n",
       "      <td>11.3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.27</td>\n",
       "      <td>10.90</td>\n",
       "      <td>0.038</td>\n",
       "      <td>29.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.99496</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.7</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.22</td>\n",
       "      <td>16.65</td>\n",
       "      <td>0.044</td>\n",
       "      <td>39.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.99855</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.48</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.39</td>\n",
       "      <td>14.20</td>\n",
       "      <td>0.058</td>\n",
       "      <td>49.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.99790</td>\n",
       "      <td>2.98</td>\n",
       "      <td>0.48</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.6</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.47</td>\n",
       "      <td>13.30</td>\n",
       "      <td>0.037</td>\n",
       "      <td>42.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.99822</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0     1     2      3      4     5      6        7     8     9     10  11\n",
       "0  9.2  0.25  0.34   1.20  0.026  31.0   93.0  0.99160  2.93  0.37  11.3   7\n",
       "1  6.6  0.20  0.27  10.90  0.038  29.0  130.0  0.99496  3.11  0.44  10.5   7\n",
       "2  5.7  0.22  0.22  16.65  0.044  39.0  110.0  0.99855  3.24  0.48   9.0   6\n",
       "3  7.2  0.23  0.39  14.20  0.058  49.0  192.0  0.99790  2.98  0.48   9.0   7\n",
       "4  7.6  0.35  0.47  13.30  0.037  42.0  116.0  0.99822  3.04  0.50   9.2   5"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df_orig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.852189</td>\n",
       "      <td>0.278565</td>\n",
       "      <td>0.333786</td>\n",
       "      <td>6.355377</td>\n",
       "      <td>0.045758</td>\n",
       "      <td>35.307849</td>\n",
       "      <td>138.007827</td>\n",
       "      <td>0.994001</td>\n",
       "      <td>3.187675</td>\n",
       "      <td>0.488185</td>\n",
       "      <td>10.513036</td>\n",
       "      <td>5.873866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.838939</td>\n",
       "      <td>0.100747</td>\n",
       "      <td>0.121491</td>\n",
       "      <td>4.981474</td>\n",
       "      <td>0.022044</td>\n",
       "      <td>17.024667</td>\n",
       "      <td>41.854932</td>\n",
       "      <td>0.002909</td>\n",
       "      <td>0.150323</td>\n",
       "      <td>0.113913</td>\n",
       "      <td>1.226730</td>\n",
       "      <td>0.882972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.900000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.987110</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.300000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>0.991720</td>\n",
       "      <td>3.090000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.800000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>0.993700</td>\n",
       "      <td>3.180000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>10.400000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.300000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>9.800000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>0.996040</td>\n",
       "      <td>3.280000</td>\n",
       "      <td>0.542500</td>\n",
       "      <td>11.400000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.200000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>31.600000</td>\n",
       "      <td>0.346000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>1.010300</td>\n",
       "      <td>3.810000</td>\n",
       "      <td>1.080000</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4   \\\n",
       "count  4408.000000  4408.000000  4408.000000  4408.000000  4408.000000   \n",
       "mean      6.852189     0.278565     0.333786     6.355377     0.045758   \n",
       "std       0.838939     0.100747     0.121491     4.981474     0.022044   \n",
       "min       3.900000     0.080000     0.000000     0.600000     0.009000   \n",
       "25%       6.300000     0.210000     0.270000     1.700000     0.036000   \n",
       "50%       6.800000     0.260000     0.310000     5.200000     0.043000   \n",
       "75%       7.300000     0.320000     0.390000     9.800000     0.050000   \n",
       "max      14.200000     1.100000     1.660000    31.600000     0.346000   \n",
       "\n",
       "                5            6            7            8            9   \\\n",
       "count  4408.000000  4408.000000  4408.000000  4408.000000  4408.000000   \n",
       "mean     35.307849   138.007827     0.994001     3.187675     0.488185   \n",
       "std      17.024667    41.854932     0.002909     0.150323     0.113913   \n",
       "min       2.000000     9.000000     0.987110     2.720000     0.220000   \n",
       "25%      23.000000   108.000000     0.991720     3.090000     0.410000   \n",
       "50%      34.000000   134.000000     0.993700     3.180000     0.470000   \n",
       "75%      46.000000   167.000000     0.996040     3.280000     0.542500   \n",
       "max     289.000000   440.000000     1.010300     3.810000     1.080000   \n",
       "\n",
       "                10           11  \n",
       "count  4408.000000  4408.000000  \n",
       "mean     10.513036     5.873866  \n",
       "std       1.226730     0.882972  \n",
       "min       8.000000     3.000000  \n",
       "25%       9.500000     5.000000  \n",
       "50%      10.400000     6.000000  \n",
       "75%      11.400000     6.000000  \n",
       "max      14.200000     9.000000  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df_orig.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cols = ['fixed_acidity', 'volatile_acidity', 'citric_acid', 'residual_sugar', 'chlorides', 'free_sulfur_dioxide', 'total_sulfur_dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df_orig.columns = df_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.026</td>\n",
       "      <td>31.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.99160</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0.37</td>\n",
       "      <td>11.3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.27</td>\n",
       "      <td>10.90</td>\n",
       "      <td>0.038</td>\n",
       "      <td>29.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.99496</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.7</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.22</td>\n",
       "      <td>16.65</td>\n",
       "      <td>0.044</td>\n",
       "      <td>39.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.99855</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.48</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.39</td>\n",
       "      <td>14.20</td>\n",
       "      <td>0.058</td>\n",
       "      <td>49.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.99790</td>\n",
       "      <td>2.98</td>\n",
       "      <td>0.48</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.6</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.47</td>\n",
       "      <td>13.30</td>\n",
       "      <td>0.037</td>\n",
       "      <td>42.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.99822</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  \\\n",
       "0            9.2              0.25         0.34            1.20      0.026   \n",
       "1            6.6              0.20         0.27           10.90      0.038   \n",
       "2            5.7              0.22         0.22           16.65      0.044   \n",
       "3            7.2              0.23         0.39           14.20      0.058   \n",
       "4            7.6              0.35         0.47           13.30      0.037   \n",
       "\n",
       "   free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  \\\n",
       "0                 31.0                  93.0  0.99160  2.93       0.37   \n",
       "1                 29.0                 130.0  0.99496  3.11       0.44   \n",
       "2                 39.0                 110.0  0.99855  3.24       0.48   \n",
       "3                 49.0                 192.0  0.99790  2.98       0.48   \n",
       "4                 42.0                 116.0  0.99822  3.04       0.50   \n",
       "\n",
       "   alcohol  quality  \n",
       "0     11.3        7  \n",
       "1     10.5        7  \n",
       "2      9.0        6  \n",
       "3      9.0        7  \n",
       "4      9.2        5  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df_orig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "      <td>4408.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.852189</td>\n",
       "      <td>0.278565</td>\n",
       "      <td>0.333786</td>\n",
       "      <td>6.355377</td>\n",
       "      <td>0.045758</td>\n",
       "      <td>35.307849</td>\n",
       "      <td>138.007827</td>\n",
       "      <td>0.994001</td>\n",
       "      <td>3.187675</td>\n",
       "      <td>0.488185</td>\n",
       "      <td>10.513036</td>\n",
       "      <td>5.873866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.838939</td>\n",
       "      <td>0.100747</td>\n",
       "      <td>0.121491</td>\n",
       "      <td>4.981474</td>\n",
       "      <td>0.022044</td>\n",
       "      <td>17.024667</td>\n",
       "      <td>41.854932</td>\n",
       "      <td>0.002909</td>\n",
       "      <td>0.150323</td>\n",
       "      <td>0.113913</td>\n",
       "      <td>1.226730</td>\n",
       "      <td>0.882972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.900000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.987110</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.300000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>0.991720</td>\n",
       "      <td>3.090000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.800000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>0.993700</td>\n",
       "      <td>3.180000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>10.400000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.300000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>9.800000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>0.996040</td>\n",
       "      <td>3.280000</td>\n",
       "      <td>0.542500</td>\n",
       "      <td>11.400000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.200000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>31.600000</td>\n",
       "      <td>0.346000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>1.010300</td>\n",
       "      <td>3.810000</td>\n",
       "      <td>1.080000</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed_acidity  volatile_acidity  citric_acid  residual_sugar  \\\n",
       "count    4408.000000       4408.000000  4408.000000     4408.000000   \n",
       "mean        6.852189          0.278565     0.333786        6.355377   \n",
       "std         0.838939          0.100747     0.121491        4.981474   \n",
       "min         3.900000          0.080000     0.000000        0.600000   \n",
       "25%         6.300000          0.210000     0.270000        1.700000   \n",
       "50%         6.800000          0.260000     0.310000        5.200000   \n",
       "75%         7.300000          0.320000     0.390000        9.800000   \n",
       "max        14.200000          1.100000     1.660000       31.600000   \n",
       "\n",
       "         chlorides  free_sulfur_dioxide  total_sulfur_dioxide      density  \\\n",
       "count  4408.000000          4408.000000           4408.000000  4408.000000   \n",
       "mean      0.045758            35.307849            138.007827     0.994001   \n",
       "std       0.022044            17.024667             41.854932     0.002909   \n",
       "min       0.009000             2.000000              9.000000     0.987110   \n",
       "25%       0.036000            23.000000            108.000000     0.991720   \n",
       "50%       0.043000            34.000000            134.000000     0.993700   \n",
       "75%       0.050000            46.000000            167.000000     0.996040   \n",
       "max       0.346000           289.000000            440.000000     1.010300   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  4408.000000  4408.000000  4408.000000  4408.000000  \n",
       "mean      3.187675     0.488185    10.513036     5.873866  \n",
       "std       0.150323     0.113913     1.226730     0.882972  \n",
       "min       2.720000     0.220000     8.000000     3.000000  \n",
       "25%       3.090000     0.410000     9.500000     5.000000  \n",
       "50%       3.180000     0.470000    10.400000     6.000000  \n",
       "75%       3.280000     0.542500    11.400000     6.000000  \n",
       "max       3.810000     1.080000    14.200000     9.000000  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df_orig.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    1987\n",
       "5    1311\n",
       "7     785\n",
       "8     153\n",
       "4     150\n",
       "3      17\n",
       "9       5\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df_orig.quality.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test - Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_train_X, wine_val_X, wine_train_Y, wine_val_Y = splitData(wine_df_orig.iloc[:,wine_df_orig.columns != 'quality'], wine_df_orig['quality'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3526.000000</td>\n",
       "      <td>3526.000000</td>\n",
       "      <td>3526.000000</td>\n",
       "      <td>3526.000000</td>\n",
       "      <td>3526.000000</td>\n",
       "      <td>3526.000000</td>\n",
       "      <td>3526.000000</td>\n",
       "      <td>3526.000000</td>\n",
       "      <td>3526.000000</td>\n",
       "      <td>3526.000000</td>\n",
       "      <td>3526.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.855062</td>\n",
       "      <td>0.279546</td>\n",
       "      <td>0.334155</td>\n",
       "      <td>6.379594</td>\n",
       "      <td>0.045625</td>\n",
       "      <td>35.309558</td>\n",
       "      <td>138.342881</td>\n",
       "      <td>0.994001</td>\n",
       "      <td>3.188616</td>\n",
       "      <td>0.488213</td>\n",
       "      <td>10.527660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.837837</td>\n",
       "      <td>0.100915</td>\n",
       "      <td>0.121400</td>\n",
       "      <td>4.985762</td>\n",
       "      <td>0.022126</td>\n",
       "      <td>17.018437</td>\n",
       "      <td>42.086619</td>\n",
       "      <td>0.002921</td>\n",
       "      <td>0.151248</td>\n",
       "      <td>0.113141</td>\n",
       "      <td>1.229251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.900000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.987110</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.300000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.712500</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>0.991700</td>\n",
       "      <td>3.090000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>9.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.800000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>134.500000</td>\n",
       "      <td>0.993730</td>\n",
       "      <td>3.180000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>10.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.300000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>9.775000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>0.996047</td>\n",
       "      <td>3.280000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>11.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.200000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>31.600000</td>\n",
       "      <td>0.346000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>1.010300</td>\n",
       "      <td>3.810000</td>\n",
       "      <td>1.080000</td>\n",
       "      <td>14.050000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed_acidity  volatile_acidity  citric_acid  residual_sugar  \\\n",
       "count    3526.000000       3526.000000  3526.000000     3526.000000   \n",
       "mean        6.855062          0.279546     0.334155        6.379594   \n",
       "std         0.837837          0.100915     0.121400        4.985762   \n",
       "min         3.900000          0.080000     0.000000        0.600000   \n",
       "25%         6.300000          0.210000     0.270000        1.712500   \n",
       "50%         6.800000          0.260000     0.320000        5.200000   \n",
       "75%         7.300000          0.320000     0.390000        9.775000   \n",
       "max        14.200000          1.100000     1.660000       31.600000   \n",
       "\n",
       "         chlorides  free_sulfur_dioxide  total_sulfur_dioxide      density  \\\n",
       "count  3526.000000          3526.000000           3526.000000  3526.000000   \n",
       "mean      0.045625            35.309558            138.342881     0.994001   \n",
       "std       0.022126            17.018437             42.086619     0.002921   \n",
       "min       0.012000             2.000000             10.000000     0.987110   \n",
       "25%       0.035000            23.000000            109.000000     0.991700   \n",
       "50%       0.043000            34.000000            134.500000     0.993730   \n",
       "75%       0.050000            46.000000            167.000000     0.996047   \n",
       "max       0.346000           289.000000            440.000000     1.010300   \n",
       "\n",
       "                pH    sulphates      alcohol  \n",
       "count  3526.000000  3526.000000  3526.000000  \n",
       "mean      3.188616     0.488213    10.527660  \n",
       "std       0.151248     0.113141     1.229251  \n",
       "min       2.720000     0.250000     8.000000  \n",
       "25%       3.090000     0.410000     9.500000  \n",
       "50%       3.180000     0.470000    10.400000  \n",
       "75%       3.280000     0.550000    11.400000  \n",
       "max       3.810000     1.080000    14.050000  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_train_X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    1608\n",
       "5    1016\n",
       "7     641\n",
       "4     123\n",
       "8     122\n",
       "3      12\n",
       "9       4\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_train_Y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One vs ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for class: 3\n",
      "Running for class: 4\n",
      "Running for class: 5\n",
      "Running for class: 6\n",
      "Running for class: 7\n",
      "Running for class: 8\n",
      "Running for class: 9\n"
     ]
    }
   ],
   "source": [
    "y_pred_final = np.array([0 for i in range(len(wine_val_Y))])\n",
    "y_pred_prob_final = np.array([0.00 for i in range(len(wine_val_Y))])\n",
    "for class_val in range(3,10):\n",
    "    print(\"Running for class: {0}\".format(class_val))\n",
    "    lr = MyLogisticRegresson(0.1, 500)\n",
    "    y_temp = wine_train_Y.copy()\n",
    "    y_temp[y_temp != class_val] = 0\n",
    "    y_temp[y_temp == class_val] = 1\n",
    "    y_val_temp = wine_val_Y.copy()\n",
    "    y_val_temp[y_val_temp != class_val] = 0\n",
    "    y_val_temp[y_val_temp == class_val] = 1\n",
    "    lr.fit(wine_train_X,y_temp)  \n",
    "    y_pred = lr.predict_probs(wine_val_X)\n",
    "    y_pred_bool = np.array(y_pred > y_pred_prob_final)\n",
    "    y_pred_final[y_pred_bool] = class_val\n",
    "    y_pred_prob_final[y_pred_bool] = y_pred[y_pred_bool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.536281179138322"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(wine_val_Y, y_pred_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONE vs ONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = wine_train_X.copy()\n",
    "df['target'] = wine_train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = wine_val_X.copy()\n",
    "df_val['target'] = wine_val_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.037</td>\n",
       "      <td>42.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.98880</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.37</td>\n",
       "      <td>12.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3128</th>\n",
       "      <td>6.7</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.32</td>\n",
       "      <td>7.90</td>\n",
       "      <td>0.034</td>\n",
       "      <td>17.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.31</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>6.7</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.117</td>\n",
       "      <td>40.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.99380</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.57</td>\n",
       "      <td>9.3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.28</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0.059</td>\n",
       "      <td>29.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0.99177</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.41</td>\n",
       "      <td>12.1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2163</th>\n",
       "      <td>6.9</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.27</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.038</td>\n",
       "      <td>33.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>0.99124</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.42</td>\n",
       "      <td>12.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  \\\n",
       "710             6.6              0.28         0.34            0.80      0.037   \n",
       "3128            6.7              0.15         0.32            7.90      0.034   \n",
       "1750            6.7              0.61         0.21            1.65      0.117   \n",
       "73              6.5              0.22         0.28            3.70      0.059   \n",
       "2163            6.9              0.44         0.27            5.00      0.038   \n",
       "\n",
       "      free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  \\\n",
       "710                  42.0                 119.0  0.98880  3.03       0.37   \n",
       "3128                 17.0                  81.0  0.99512  3.29       0.31   \n",
       "1750                 40.0                 240.0  0.99380  3.11       0.57   \n",
       "73                   29.0                 151.0  0.99177  3.23       0.41   \n",
       "2163                 33.0                 166.0  0.99124  3.20       0.42   \n",
       "\n",
       "      alcohol  target  \n",
       "710      12.5       6  \n",
       "3128     10.0       6  \n",
       "1750      9.3       5  \n",
       "73       12.1       7  \n",
       "2163     12.2       6  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for classes: 3, 4\n",
      "Running for classes: 3, 5\n",
      "Running for classes: 3, 6\n",
      "Running for classes: 3, 7\n",
      "Running for classes: 3, 8\n",
      "Running for classes: 3, 9\n",
      "Running for classes: 4, 3\n",
      "Running for classes: 4, 5\n",
      "Running for classes: 4, 6\n",
      "Running for classes: 4, 7\n",
      "Running for classes: 4, 8\n",
      "Running for classes: 4, 9\n",
      "Running for classes: 5, 3\n",
      "Running for classes: 5, 4\n",
      "Running for classes: 5, 6\n",
      "Running for classes: 5, 7\n",
      "Running for classes: 5, 8\n",
      "Running for classes: 5, 9\n",
      "Running for classes: 6, 3\n",
      "Running for classes: 6, 4\n",
      "Running for classes: 6, 5\n",
      "Running for classes: 6, 7\n",
      "Running for classes: 6, 8\n",
      "Running for classes: 6, 9\n",
      "Running for classes: 7, 3\n",
      "Running for classes: 7, 4\n",
      "Running for classes: 7, 5\n",
      "Running for classes: 7, 6\n",
      "Running for classes: 7, 8\n",
      "Running for classes: 7, 9\n",
      "Running for classes: 8, 3\n",
      "Running for classes: 8, 4\n",
      "Running for classes: 8, 5\n",
      "Running for classes: 8, 6\n",
      "Running for classes: 8, 7\n",
      "Running for classes: 8, 9\n",
      "Running for classes: 9, 3\n",
      "Running for classes: 9, 4\n",
      "Running for classes: 9, 5\n",
      "Running for classes: 9, 6\n",
      "Running for classes: 9, 7\n",
      "Running for classes: 9, 8\n"
     ]
    }
   ],
   "source": [
    "y_pred_counts = np.array([defaultdict(int) for i in range(len(wine_val_Y))])\n",
    "perm = permutations(list(range(3,10)), 2)\n",
    "for class_a, class_b in perm:\n",
    "    if(class_a == class_b):\n",
    "        continue\n",
    "    print(\"Running for classes: {0}, {1}\".format(class_a, class_b))\n",
    "\n",
    "    '''\n",
    "    Setting up temporary X_train and Y_train\n",
    "    '''\n",
    "    df_train = df[(df['target'] == class_a) | (df['target'] == class_b)]\n",
    "    x_temp = df_train.iloc[:,df_train.columns != 'target'].copy()\n",
    "    y_temp = df_train.iloc[:,df_train.columns == 'target'].copy()\n",
    "    y_temp[y_temp != class_a] = 0\n",
    "    y_temp[y_temp == class_a] = 1\n",
    "\n",
    "    '''\n",
    "    Setting up temporary X_val and Y_val\n",
    "    '''\n",
    "    df_temp = df_val#[(df_val['target'] == class_a) | (df_val['target'] == class_b)]\n",
    "    x_val_temp = df_temp.iloc[:,df_temp.columns != 'target'].copy()\n",
    "    y_val_temp = df_temp.iloc[:,df_temp.columns == 'target'].copy()\n",
    "    y_val_temp[y_val_temp != class_a] = 0\n",
    "    y_val_temp[y_val_temp == class_a] = 1\n",
    "\n",
    "    '''\n",
    "    Model Training\n",
    "    '''      \n",
    "    lr = MyLogisticRegresson(0.1, 500)\n",
    "    lr.fit(x_temp,y_temp)  \n",
    "    y_pred = np.array(lr.predict(x_val_temp))\n",
    "    for i, y in enumerate(y_pred):\n",
    "        if(int(y) == 1):\n",
    "            y_pred_counts[i][class_a] += 1\n",
    "        else:\n",
    "            y_pred_counts[i][class_b] += 1\n",
    "\n",
    "y_pred_final = [max(d, key=lambda k: d[k]) if bool(d) == True else None for d in y_pred_counts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5396825396825397"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_pred_final, wine_val_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
