{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qh1Mk6st3YGX",
    "outputId": "3870d975-28a9-4ec8-d417-b99a60027489"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation,LSTM,Dense\n",
    "from keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.callbacks import LambdaCallback, ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BPrKqrBQ3YGb"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('songdata.csv')['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1071
    },
    "colab_type": "code",
    "id": "SDi8Ib7n3YGe",
    "outputId": "a03b5283-fe14-4c8d-a3b6-bed1eecc91dc",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                                 57650\n",
       "unique                                                57494\n",
       "top       Chestnuts roasting on an open fire  \\nJack Fro...\n",
       "freq                                                      6\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "FiRMBW6x3YGi",
    "outputId": "a5e745dd-7f57-431a-979f-1f3b0282e24e"
   },
   "outputs": [],
   "source": [
    "data=np.array(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9qzGPjvI3YGl"
   },
   "outputs": [],
   "source": [
    "corpus=''\n",
    "for ix in range(len(data)):\n",
    "    corpus+=data[ix]\n",
    "corpus = corpus.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rho43V-J3YGr"
   },
   "outputs": [],
   "source": [
    "vocab=list(set(corpus))\n",
    "char_ix={c:i for i,c in enumerate(vocab)}\n",
    "ix_char={i:c for i,c in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-4QBRHy13YGu",
    "outputId": "26271d9b-ac64-404a-ca55-822564a561b0",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 16,\n",
       " ' ': 20,\n",
       " '!': 5,\n",
       " '\"': 30,\n",
       " \"'\": 18,\n",
       " '(': 4,\n",
       " ')': 22,\n",
       " ',': 14,\n",
       " '-': 23,\n",
       " '.': 42,\n",
       " '0': 29,\n",
       " '1': 37,\n",
       " '2': 41,\n",
       " '3': 11,\n",
       " '4': 43,\n",
       " '5': 10,\n",
       " '6': 44,\n",
       " '7': 27,\n",
       " '8': 31,\n",
       " '9': 7,\n",
       " ':': 0,\n",
       " '?': 26,\n",
       " '[': 28,\n",
       " ']': 47,\n",
       " 'a': 46,\n",
       " 'b': 9,\n",
       " 'c': 32,\n",
       " 'd': 15,\n",
       " 'e': 6,\n",
       " 'f': 12,\n",
       " 'g': 36,\n",
       " 'h': 21,\n",
       " 'i': 13,\n",
       " 'j': 8,\n",
       " 'k': 34,\n",
       " 'l': 17,\n",
       " 'm': 2,\n",
       " 'n': 1,\n",
       " 'o': 25,\n",
       " 'p': 19,\n",
       " 'q': 45,\n",
       " 'r': 3,\n",
       " 's': 35,\n",
       " 't': 33,\n",
       " 'u': 39,\n",
       " 'v': 49,\n",
       " 'w': 24,\n",
       " 'x': 38,\n",
       " 'y': 48,\n",
       " 'z': 40}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FDWiKD1T3YG3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "maxlen=40\n",
    "vocab_size=len(vocab)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X46FgeuG3YG6"
   },
   "outputs": [],
   "source": [
    "sentences=[]\n",
    "next_char=[]\n",
    "for i in range(len(corpus)-maxlen-1):\n",
    "    sentences.append(corpus[i:i+maxlen])\n",
    "    next_char.append(corpus[i+maxlen])\n",
    "split_count = int(0.02 * 67998416)\n",
    "sentences_test = sentences[split_count:]\n",
    "next_char_test = next_char[split_count:]\n",
    "sentences = sentences[:split_count]\n",
    "next_char = next_char[:split_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(sentence_list, next_word_list, batch_size):\n",
    "    index = 0\n",
    "    while True:\n",
    "        x = np.zeros((batch_size, maxlen, vocab_size), dtype=np.bool)\n",
    "        y = np.zeros((batch_size, vocab_size), dtype=np.bool)\n",
    "        for i in range(batch_size):\n",
    "            for t, w in enumerate(sentence_list[index]):\n",
    "                x[i, t, char_ix[w]] = 1\n",
    "            y[i, char_ix[next_word_list[index]]] = 1\n",
    "\n",
    "            index = index + 1\n",
    "            if index == len(sentence_list):\n",
    "                index = 0\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mGj6PbK-3YHP",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/amanjoshi668/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               91648     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 50)                0         \n",
      "=================================================================\n",
      "Total params: 98,098\n",
      "Trainable params: 98,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(LSTM(128,input_shape=(maxlen,vocab_size)))\n",
    "model.add(Dense(vocab_size))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "model.compile(optimizer=Adam(lr=0.01),loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, logs):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    examples_file.write('\\n----- Generating text after Epoch: %d\\n' % epoch)\n",
    "\n",
    "    # Randomly pick a seed sequence\n",
    "    seed_index = np.random.randint(len(sentences+sentences_test))\n",
    "    seed = (sentences+sentences_test)[seed_index]\n",
    "\n",
    "    for diversity in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "        sentence = seed\n",
    "        examples_file.write('----- Diversity:' + str(diversity) + '\\n')\n",
    "        examples_file.write('----- Generating with seed:\\n\"' + ' '.join(sentence) + '\"\\n')\n",
    "        examples_file.write(' '.join(sentence))\n",
    "\n",
    "        for i in range(50):\n",
    "            x_pred = np.zeros((1, maxlen))\n",
    "            for t, word in enumerate(sentence):\n",
    "                x_pred[0, t] = word_indices[word]\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_word = indices_word[next_index]\n",
    "\n",
    "            sentence = sentence[1:]\n",
    "            sentence.append(next_word)\n",
    "\n",
    "            examples_file.write(\" \"+next_word)\n",
    "        examples_file.write('\\n')\n",
    "    examples_file.write('='*80 + '\\n')\n",
    "    examples_file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1yMxsErg3YHU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/amanjoshi668/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      " 2590/10625 [======>.......................] - ETA: 14:37 - loss: 1.7666"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "file_path = \"./checkpoints/LSTM_LYRICS-epoch{epoch:03d}-words%d-sequence%d-minfreq%d-loss{loss:.4f}-acc{acc:.4f}-val_loss{val_loss:.4f}-val_acc{val_acc:.4f}\" % (\n",
    "    len(vocab),\n",
    "    40,\n",
    "    10\n",
    ")\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', save_best_only=True)\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=5)\n",
    "callbacks_list = [checkpoint, print_callback, early_stopping]\n",
    "model.fit_generator(generator(sentences, next_char, BATCH_SIZE),\n",
    "    steps_per_epoch=int(len(sentences)/BATCH_SIZE) + 1,\n",
    "    epochs=10,\n",
    "    callbacks=callbacks_list,\n",
    "    validation_data=generator(sentences_test, next_char_test, BATCH_SIZE)\n",
    "                    ,validation_steps=int(len(sentences_test)/BATCH_SIZE) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "70L9BUE23YHY",
    "outputId": "cc040da6-1b15-487f-c9da-47404be44dcd"
   },
   "outputs": [],
   "source": [
    "#serialize model to JSON  serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sssDDxa23YHc"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "txt = corpus\n",
    "generated=''\n",
    "start_index=random.randint(0,len(txt)-maxlen-1)\n",
    "sent=txt[start_index:start_index+maxlen]\n",
    "generated+=sent\n",
    "for i in range(1900):\n",
    "    x_sample=generated[i:i+maxlen]\n",
    "    x=np.zeros((1,maxlen,vocab_size))\n",
    "    for j in range(maxlen):\n",
    "        x[0,j,char_ix[x_sample[j]]]=1\n",
    "    probs=model.predict(x)\n",
    "    probs=np.reshape(probs,probs.shape[1])\n",
    "    ix=np.random.choice(range(vocab_size),p=probs.ravel())\n",
    "    generated+=ix_char[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xj3Yj52D3YHe",
    "outputId": "30c25b64-35a4-49e7-a1fa-8ba4c677cc9c"
   },
   "outputs": [],
   "source": [
    "print(generated)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "lyric_generator_by_character.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
